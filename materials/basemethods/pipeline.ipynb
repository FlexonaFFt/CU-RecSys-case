{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9713ced",
   "metadata": {},
   "source": [
    "# Базовый солюшн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a7cd139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, List\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a5282",
   "metadata": {},
   "source": [
    "### Метрики оценивания моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bc75e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validator(ABC):\n",
    "    def __init__(self, train: pd.DataFrame, test: pd.DataFrame, cold_items: set = None):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.cold_items = cold_items or set()\n",
    "\n",
    "    @abstractmethod\n",
    "    def evaluate(self, predictions: Dict[int, List[int]]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        predictions: dict user_id -> list of recommended item_ids\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def recall_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        return len(set(y_true) & set(y_pred[:k])) / len(set(y_true)) if y_true else 0.0\n",
    "\n",
    "    def precision_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        return len(set(y_true) & set(y_pred[:k])) / k if y_true else 0.0\n",
    "\n",
    "    def hitrate_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        return 1.0 if len(set(y_true) & set(y_pred[:k])) > 0 else 0.0\n",
    "\n",
    "    def ndcg_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        dcg = 0.0\n",
    "        for i, item in enumerate(y_pred[:k]):\n",
    "            if item in y_true:\n",
    "                dcg += 1 / np.log2(i + 2)\n",
    "        idcg = sum(1 / np.log2(i + 2) for i in range(min(len(y_true), k)))\n",
    "        return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    def mrr_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        for i, item in enumerate(y_pred[:k]):\n",
    "            if item in y_true:\n",
    "                return 1 / (i + 1)\n",
    "        return 0.0\n",
    "\n",
    "    def coverage(self, predictions: Dict[int, List[int]]) -> float:\n",
    "        all_pred_items = set(item for recs in predictions.values() for item in recs)\n",
    "        all_train_items = set(self.train[\"item_id\"].unique())\n",
    "        return len(all_pred_items) / len(all_train_items)\n",
    "\n",
    "    @staticmethod\n",
    "    def print_metrics(metrics: Dict[str, float]):\n",
    "        print(\"\\n=== Evaluation Results ===\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"{key:<15}: {value:.4f}\")\n",
    "        print(\"==========================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01662f85",
   "metadata": {},
   "source": [
    "Стоит разделить валидацию на две версии, для сравнения. Моя гипотеза заключается в том, что совместная валидация warm и cold может быть не совсем честной. Например, если в тесте 90% warm и 10% cold, то Recall@10 в среднем будет определяться warm-айтемами. Модель может полностью «забыть» про cold items, но в отчёте всё равно будут хорошие цифры. Это вводит в заблуждение: кажется, что модель универсальная, хотя на самом деле cold-start не решён."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f7d849",
   "metadata": {},
   "source": [
    "#### Блок совместной валидации (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64a70b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointValidator(Validator):\n",
    "    def __init__(self, train: pl.DataFrame, test: pl.DataFrame, cold_items: set = None):\n",
    "        super().__init__(train, test, cold_items)\n",
    "        self.user2items = (\n",
    "            test.group_by(\"user_id\").agg(pl.col(\"item_id\")).to_dict(as_series=False)\n",
    "        )\n",
    "        self.user2items = dict(zip(self.user2items[\"user_id\"], self.user2items[\"item_id\"]))\n",
    "\n",
    "    def evaluate(self, predictions: Dict[int, List[int]]) -> Dict[str, float]:\n",
    "        recalls, precisions, hits, ndcgs, mrrs = [], [], [], [], []\n",
    "        for user_id, y_pred in predictions.items():\n",
    "            y_true = self.user2items.get(user_id, [])\n",
    "            recalls.append(self.recall_at_k(y_true, y_pred))\n",
    "            precisions.append(self.precision_at_k(y_true, y_pred))\n",
    "            hits.append(self.hitrate_at_k(y_true, y_pred))\n",
    "            ndcgs.append(self.ndcg_at_k(y_true, y_pred))\n",
    "            mrrs.append(self.mrr_at_k(y_true, y_pred))\n",
    "        results = {\n",
    "            \"Recall@10\": np.mean(recalls),\n",
    "            \"Precision@10\": np.mean(precisions),\n",
    "            \"HitRate@10\": np.mean(hits),\n",
    "            \"NDCG@10\": np.mean(ndcgs),\n",
    "            \"MRR@10\": np.mean(mrrs),\n",
    "            \"Coverage\": self.coverage(predictions),\n",
    "        }\n",
    "        self.print_metrics(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fbe954",
   "metadata": {},
   "source": [
    "#### Разделенная валидация (cold vs warm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fceeeaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitValidator(Validator):\n",
    "    def __init__(self, train: pl.DataFrame, test: pl.DataFrame, cold_items: set = None):\n",
    "        super().__init__(train, test, cold_items)\n",
    "        self.user2items = (\n",
    "            test.group_by(\"user_id\").agg(pl.col(\"item_id\")).to_dict(as_series=False)\n",
    "        )\n",
    "        self.user2items = dict(zip(self.user2items[\"user_id\"], self.user2items[\"item_id\"]))\n",
    "\n",
    "    def evaluate(self, predictions: Dict[int, List[int]]) -> Dict[str, float]:\n",
    "        results = {}\n",
    "        for subset in [\"cold\", \"warm\"]:\n",
    "            recalls, precisions, hits, ndcgs, mrrs = [], [], [], [], []\n",
    "            for user_id, y_pred in predictions.items():\n",
    "                y_true = self.user2items.get(user_id, [])\n",
    "                if not y_true:\n",
    "                    continue\n",
    "                if subset == \"cold\":\n",
    "                    y_true = [i for i in y_true if i in self.cold_items]\n",
    "                elif subset == \"warm\":\n",
    "                    y_true = [i for i in y_true if i not in self.cold_items]\n",
    "                if not y_true:\n",
    "                    continue\n",
    "                recalls.append(self.recall_at_k(y_true, y_pred))\n",
    "                precisions.append(self.precision_at_k(y_true, y_pred))\n",
    "                hits.append(self.hitrate_at_k(y_true, y_pred))\n",
    "                ndcgs.append(self.ndcg_at_k(y_true, y_pred))\n",
    "                mrrs.append(self.mrr_at_k(y_true, y_pred))\n",
    "            results[f\"Recall@10_{subset}\"] = np.mean(recalls) if recalls else 0.0\n",
    "            results[f\"Precision@10_{subset}\"] = np.mean(precisions) if precisions else 0.0\n",
    "            results[f\"HitRate@10_{subset}\"] = np.mean(hits) if hits else 0.0\n",
    "            results[f\"NDCG@10_{subset}\"] = np.mean(ndcgs) if ndcgs else 0.0\n",
    "            results[f\"MRR@10_{subset}\"] = np.mean(mrrs) if mrrs else 0.0\n",
    "        results[\"Coverage\"] = self.coverage(predictions)\n",
    "        self.print_metrics(results)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b15366b",
   "metadata": {},
   "source": [
    "### Базовые методы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17f65c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemPopRecSys:\n",
    "    def __init__(self, train: pd.DataFrame):\n",
    "        self.train = train\n",
    "        self.popular_items = None\n",
    "\n",
    "    def fit(self):\n",
    "        # Считаем популярность айтемов по числу взаимодействий\n",
    "        popularity = self.train.groupby(\"item_id\").size().reset_index(name=\"count\")\n",
    "        popularity = popularity.sort_values(\"count\", ascending=False)\n",
    "        self.popular_items = popularity[\"item_id\"].tolist()\n",
    "\n",
    "    def recommend(self, user_ids: List[int], k: int = 10) -> Dict[int, List[int]]:\n",
    "        if self.popular_items is None:\n",
    "            raise ValueError(\"Model is not fitted. Call fit() before recommend().\")\n",
    "        preds = {u: self.popular_items[:k] for u in user_ids}\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8239bb1",
   "metadata": {},
   "source": [
    "##### Проблематика ItemPopRecSys и cold-start\n",
    "\n",
    "* `ItemPopRecSys` - рекомендует только книги, которые были в train.\n",
    "* Но cold items (которые есть только в test) он никогда не предложит.\n",
    "* __Это особенность__ - все чисто коллаборативные методы не умеют cold-start без дополнительных фичей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff1a8322",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserKNNRecSys:\n",
    "    def __init__(self, train: pl.DataFrame, k_neighbors: int = 20):\n",
    "        self.train = train\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.user2items = None\n",
    "\n",
    "    def fit(self):\n",
    "        df = self.train.to_pandas()\n",
    "        self.user2items = df.groupby(\"user_id\")[\"item_id\"].apply(set).to_dict()\n",
    "\n",
    "    def recommend(self, user_ids: List[int], k: int = 10) -> Dict[int, List[int]]:\n",
    "        preds = {}\n",
    "        for u in user_ids:\n",
    "            if u not in self.user2items:\n",
    "                preds[u] = []\n",
    "                continue\n",
    "            # считаем схожесть с другими пользователями\n",
    "            scores = defaultdict(int)\n",
    "            for v, items in self.user2items.items():\n",
    "                if u == v:\n",
    "                    continue\n",
    "                common = len(self.user2items[u] & items)\n",
    "                if common > 0:\n",
    "                    for it in items:\n",
    "                        if it not in self.user2items[u]:\n",
    "                            scores[it] += common\n",
    "            recs = sorted(scores, key=scores.get, reverse=True)[:k]\n",
    "            preds[u] = recs\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff180d52",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17c48852",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemKNNRecSys:\n",
    "    def __init__(self, train: pl.DataFrame, k_neighbors: int = 20):\n",
    "        self.train = train\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.item2users = None\n",
    "\n",
    "    def fit(self):\n",
    "        df = self.train.to_pandas()\n",
    "        self.item2users = df.groupby(\"item_id\")[\"user_id\"].apply(set).to_dict()\n",
    "\n",
    "    def recommend(self, user_ids: List[int], k: int = 10) -> Dict[int, List[int]]:\n",
    "        df = self.train.to_pandas()\n",
    "        user2items = df.groupby(\"user_id\")[\"item_id\"].apply(set).to_dict()\n",
    "        preds = {}\n",
    "        for u in user_ids:\n",
    "            if u not in user2items:\n",
    "                preds[u] = []\n",
    "                continue\n",
    "            scores = defaultdict(int)\n",
    "            for it in user2items[u]:\n",
    "                if it not in self.item2users:\n",
    "                    continue\n",
    "                users_who_liked = self.item2users[it]\n",
    "                for other_item, other_users in self.item2users.items():\n",
    "                    if other_item in user2items[u]:\n",
    "                        continue\n",
    "                    common = len(users_who_liked & other_users)\n",
    "                    if common > 0:\n",
    "                        scores[other_item] += common\n",
    "            recs = sorted(scores, key=scores.get, reverse=True)[:k]\n",
    "            preds[u] = recs\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd395434",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc71207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostRecentItemsRecSys:\n",
    "    def __init__(self, items_metadata: pl.DataFrame, time_col: str = \"timestamp\"):\n",
    "        self.items_metadata = items_metadata\n",
    "        self.time_col = time_col\n",
    "        self.sorted_items = None\n",
    "\n",
    "    def fit(self):\n",
    "        self.sorted_items = (\n",
    "            self.items_metadata.sort(self.time_col, descending=True)[\"item_id\"].to_list()\n",
    "        )\n",
    "\n",
    "    def recommend(self, user_ids: List[int], k: int = 10) -> Dict[int, List[int]]:\n",
    "        if self.sorted_items is None:\n",
    "            raise ValueError(\"Model is not fitted. Call fit() before recommend().\")\n",
    "        return {u: self.sorted_items[:k] for u in user_ids}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2919327b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4c139f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomColdRecSys:\n",
    "    def __init__(self, cold_items: List[int], seed: int = 42):\n",
    "        self.cold_items = cold_items\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "    def fit(self):\n",
    "        pass\n",
    "\n",
    "    def recommend(self, user_ids: List[int], k: int = 10) -> Dict[int, List[int]]:\n",
    "        return {\n",
    "            u: self.rng.choice(self.cold_items, size=min(k, len(self.cold_items)), replace=False).tolist()\n",
    "            for u in user_ids\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cc2924",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bc68b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridPopColdRecSys:\n",
    "    def __init__(self, train: pl.DataFrame, cold_items: List[int]):\n",
    "        self.train = train\n",
    "        self.cold_items = cold_items\n",
    "        self.popular_items = None\n",
    "\n",
    "    def fit(self):\n",
    "        popularity = (\n",
    "            self.train.group_by(\"item_id\").len().sort(\"len\", descending=True)\n",
    "        )\n",
    "        self.popular_items = popularity[\"item_id\"].to_list()\n",
    "\n",
    "    def recommend(self, user_ids: List[int], k: int = 10) -> Dict[int, List[int]]:\n",
    "        preds = {}\n",
    "        for u in user_ids:\n",
    "            recs = self.popular_items[: k // 2]\n",
    "            if self.cold_items:\n",
    "                recs += list(np.random.choice(self.cold_items, size=min(k - len(recs), len(self.cold_items)), replace=False))\n",
    "            preds[u] = recs[:k]\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb8b02",
   "metadata": {},
   "source": [
    "#### Вспомогательная функция для удобного представления результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce3f56bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(models: dict, test: pl.DataFrame, n: int = 5, verbose: bool = True):\n",
    "    user2items = (\n",
    "        test.group_by(\"user_id\").agg(pl.col(\"item_id\")).to_dict(as_series=False)\n",
    "    )\n",
    "    user2items = dict(zip(user2items[\"user_id\"], user2items[\"item_id\"]))\n",
    "    rows = []\n",
    "    for i, (user, items) in enumerate(user2items.items()):\n",
    "        if i >= n:\n",
    "            break\n",
    "        row = {\"user_id\": user, \"item_id\": items}\n",
    "        for model_name, preds in models.items():\n",
    "            row[model_name] = preds.get(user, [])\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pl.DataFrame(rows)\n",
    "    if verbose:\n",
    "        print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e1a315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train users: 349719, items: 31300\n",
      "Test users: 185828, items: 27367\n",
      "Cold items: 1775\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'groupby'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCold items: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cold_items)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m ItemPopRecSys(train)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m user_ids \u001b[38;5;241m=\u001b[39m test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m     17\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mrecommend(user_ids, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m, in \u001b[0;36mItemPopRecSys.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Считаем популярность айтемов по числу взаимодействий\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     popularity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mreset_index(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     popularity \u001b[38;5;241m=\u001b[39m popularity\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopular_items \u001b[38;5;241m=\u001b[39m popularity[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'groupby'"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "train = pl.read_parquet(\"../../data/train.pq\")\n",
    "test = pl.read_parquet(\"../../data/test.pq\")\n",
    "\n",
    "train_items = set(train[\"item_id\"].unique())\n",
    "test_items = set(test[\"item_id\"].unique())\n",
    "cold_items = test_items - train_items\n",
    "\n",
    "print(f\"Train users: {train['user_id'].n_unique()}, items: {len(train_items)}\")\n",
    "print(f\"Test users: {test['user_id'].n_unique()}, items: {len(test_items)}\")\n",
    "print(f\"Cold items: {len(cold_items)}\")\n",
    "\n",
    "model = ItemPopRecSys(train)\n",
    "model.fit()\n",
    "user_ids = test[\"user_id\"].unique().to_list()\n",
    "predictions = model.recommend(user_ids, k=10)\n",
    "\n",
    "print(\"Joint validation:\")\n",
    "joint_val = JointValidator(train, test, cold_items)\n",
    "joint_val.evaluate(predictions)\n",
    "\n",
    "print(\"Split validation (cold vs warm):\")\n",
    "split_val = SplitValidator(train, test, cold_items)\n",
    "split_val.evaluate(predictions)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
