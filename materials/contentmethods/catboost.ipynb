{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25497418",
   "metadata": {},
   "source": [
    "# Контентные методы "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688bfe8",
   "metadata": {},
   "source": [
    "### Базовые операции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2afc3887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os \n",
    "import logging\n",
    "import joblib\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, List\n",
    "from collections import defaultdict, Counter \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "os.makedirs('../models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aecb716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сразу загружу данные\n",
    "train = pl.read_parquet(\"../../data/train.pq\")\n",
    "test = pl.read_parquet(\"../../data/test.pq\")\n",
    "books = pl.read_parquet(\"../../data/books.pq\")\n",
    "\n",
    "train_items = set(train[\"item_id\"].unique())\n",
    "test_items = set(test[\"item_id\"].unique())\n",
    "cold_items = test_items - train_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc86f568",
   "metadata": {},
   "source": [
    "#### Метрики оценивания моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b46c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validator(ABC):\n",
    "    def __init__(self, train: pd.DataFrame, test: pd.DataFrame, cold_items: set = None):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.cold_items = cold_items or set()\n",
    "\n",
    "    @abstractmethod\n",
    "    def evaluate(self, predictions: Dict[int, List[int]]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        predictions: dict user_id -> list of recommended item_ids\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def recall_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        return len(set(y_true) & set(y_pred[:k])) / len(set(y_true)) if y_true else 0.0\n",
    "\n",
    "    def precision_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        return len(set(y_true) & set(y_pred[:k])) / k if y_true else 0.0\n",
    "\n",
    "    def hitrate_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        return 1.0 if len(set(y_true) & set(y_pred[:k])) > 0 else 0.0\n",
    "\n",
    "    def ndcg_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        dcg = 0.0\n",
    "        for i, item in enumerate(y_pred[:k]):\n",
    "            if item in y_true:\n",
    "                dcg += 1 / np.log2(i + 2)\n",
    "        idcg = sum(1 / np.log2(i + 2) for i in range(min(len(y_true), k)))\n",
    "        return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    def mrr_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        for i, item in enumerate(y_pred[:k]):\n",
    "            if item in y_true:\n",
    "                return 1 / (i + 1)\n",
    "        return 0.0\n",
    "\n",
    "    def coverage(self, predictions: Dict[int, List[int]]) -> float:\n",
    "        all_pred_items = set(item for recs in predictions.values() for item in recs)\n",
    "        all_train_items = set(self.train[\"item_id\"].unique())\n",
    "        return len(all_pred_items) / len(all_train_items)\n",
    "\n",
    "    @staticmethod\n",
    "    def print_metrics(metrics: Dict[str, float]):\n",
    "        print(\"\\n=== Evaluation Results ===\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"{key:<15}: {value:.4f}\")\n",
    "        print(\"==========================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7e5b41",
   "metadata": {},
   "source": [
    "Стоит разделить валидацию на две версии, для сравнения. Моя гипотеза заключается в том, что совместная валидация warm и cold может быть не совсем честной. Например, если в тесте 90% warm и 10% cold, то Recall@10 в среднем будет определяться warm-айтемами. Модель может полностью «забыть» про cold items, но в отчёте всё равно будут хорошие цифры. Это вводит в заблуждение: кажется, что модель универсальная, хотя на самом деле cold-start не решён."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada31206",
   "metadata": {},
   "source": [
    "#### Блок совместной валидации (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8fd76c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointValidator(Validator):\n",
    "    def __init__(self, train: pl.DataFrame, test: pl.DataFrame, cold_items: set = None):\n",
    "        super().__init__(train, test, cold_items)\n",
    "        self.user2items = (\n",
    "            test.group_by(\"user_id\").agg(pl.col(\"item_id\")).to_dict(as_series=False)\n",
    "        )\n",
    "        self.user2items = dict(zip(self.user2items[\"user_id\"], self.user2items[\"item_id\"]))\n",
    "\n",
    "    def evaluate(self, predictions: Dict[int, List[int]]) -> Dict[str, float]:\n",
    "        recalls, precisions, hits, ndcgs, mrrs = [], [], [], [], []\n",
    "        for user_id, y_pred in predictions.items():\n",
    "            y_true = self.user2items.get(user_id, [])\n",
    "            recalls.append(self.recall_at_k(y_true, y_pred))\n",
    "            precisions.append(self.precision_at_k(y_true, y_pred))\n",
    "            hits.append(self.hitrate_at_k(y_true, y_pred))\n",
    "            ndcgs.append(self.ndcg_at_k(y_true, y_pred))\n",
    "            mrrs.append(self.mrr_at_k(y_true, y_pred))\n",
    "        results = {\n",
    "            \"Recall@10\": np.mean(recalls),\n",
    "            \"Precision@10\": np.mean(precisions),\n",
    "            \"HitRate@10\": np.mean(hits),\n",
    "            \"NDCG@10\": np.mean(ndcgs),\n",
    "            \"MRR@10\": np.mean(mrrs),\n",
    "            \"Coverage\": self.coverage(predictions),\n",
    "        }\n",
    "        self.print_metrics(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19c9d8c",
   "metadata": {},
   "source": [
    "#### Разделенная валидация (cold vs warm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4fcf8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitValidator(Validator):\n",
    "    def __init__(self, train: pl.DataFrame, test: pl.DataFrame, cold_items: set = None):\n",
    "        super().__init__(train, test, cold_items)\n",
    "        self.user2items = (\n",
    "            test.group_by(\"user_id\").agg(pl.col(\"item_id\")).to_dict(as_series=False)\n",
    "        )\n",
    "        self.user2items = dict(zip(self.user2items[\"user_id\"], self.user2items[\"item_id\"]))\n",
    "\n",
    "    def evaluate(self, predictions: Dict[int, List[int]]) -> Dict[str, float]:\n",
    "        results = {}\n",
    "        for subset in [\"cold\", \"warm\"]:\n",
    "            recalls, precisions, hits, ndcgs, mrrs = [], [], [], [], []\n",
    "            for user_id, y_pred in predictions.items():\n",
    "                y_true = self.user2items.get(user_id, [])\n",
    "                if not y_true:\n",
    "                    continue\n",
    "                if subset == \"cold\":\n",
    "                    y_true = [i for i in y_true if i in self.cold_items]\n",
    "                elif subset == \"warm\":\n",
    "                    y_true = [i for i in y_true if i not in self.cold_items]\n",
    "                if not y_true:\n",
    "                    continue\n",
    "                recalls.append(self.recall_at_k(y_true, y_pred))\n",
    "                precisions.append(self.precision_at_k(y_true, y_pred))\n",
    "                hits.append(self.hitrate_at_k(y_true, y_pred))\n",
    "                ndcgs.append(self.ndcg_at_k(y_true, y_pred))\n",
    "                mrrs.append(self.mrr_at_k(y_true, y_pred))\n",
    "            results[f\"Recall@10_{subset}\"] = np.mean(recalls) if recalls else 0.0\n",
    "            results[f\"Precision@10_{subset}\"] = np.mean(precisions) if precisions else 0.0\n",
    "            results[f\"HitRate@10_{subset}\"] = np.mean(hits) if hits else 0.0\n",
    "            results[f\"NDCG@10_{subset}\"] = np.mean(ndcgs) if ndcgs else 0.0\n",
    "            results[f\"MRR@10_{subset}\"] = np.mean(mrrs) if mrrs else 0.0\n",
    "        results[\"Coverage\"] = self.coverage(predictions)\n",
    "        self.print_metrics(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5488f3",
   "metadata": {},
   "source": [
    "#### Вспомогательные функции для удобного представления результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37d934e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shorten_list(lst, max_len=10):\n",
    "    \"\"\"Обрезает длинные списки для красивого вывода\"\"\"\n",
    "    if lst is None:\n",
    "        return []\n",
    "    return lst[:max_len] if len(lst) > max_len else lst\n",
    "\n",
    "def show_predictions(models: dict, data: pl.DataFrame, n=5, verbose=True, is_val=False):\n",
    "    df = data.sample(n).select([\"user_id\", \"item_id\"])\n",
    "    if is_val:\n",
    "        df = df.rename({\"item_id\": \"true_items\"})\n",
    "\n",
    "    # добавляем предсказания\n",
    "    for name, preds in models.items():\n",
    "        df = df.with_columns(\n",
    "            pl.col(\"user_id\").map_elements(\n",
    "                lambda u: _shorten_list(preds.get(u, [])), \n",
    "                return_dtype=pl.List(pl.Int64)\n",
    "            ).alias(name)\n",
    "        )\n",
    "\n",
    "    if verbose:\n",
    "        print(df.shape)\n",
    "        print(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def val_predictions(models: dict, val: pl.DataFrame, validator: Validator, k: int = 10, verbose: bool = True):\n",
    "    results = []\n",
    "    user2items = (\n",
    "        val.group_by(\"user_id\").agg(pl.col(\"item_id\")).to_dict(as_series=False)\n",
    "    )\n",
    "    user2items = dict(zip(user2items[\"user_id\"], user2items[\"item_id\"]))\n",
    "\n",
    "    for model_name, preds in models.items():\n",
    "        recalls, precisions, hits, ndcgs, mrrs = [], [], [], [], []\n",
    "        for u, y_true in user2items.items():\n",
    "            y_pred = preds.get(u, [])\n",
    "            recalls.append(validator.recall_at_k(y_true, y_pred, k))\n",
    "            precisions.append(validator.precision_at_k(y_true, y_pred, k))\n",
    "            hits.append(validator.hitrate_at_k(y_true, y_pred, k))\n",
    "            ndcgs.append(validator.ndcg_at_k(y_true, y_pred, k))\n",
    "            mrrs.append(validator.mrr_at_k(y_true, y_pred, k))\n",
    "        metrics = {\n",
    "            \"model\": model_name,\n",
    "            \"Recall@10\": np.mean(recalls),\n",
    "            \"Precision@10\": np.mean(precisions),\n",
    "            \"HitRate@10\": np.mean(hits),\n",
    "            \"NDCG@10\": np.mean(ndcgs),\n",
    "            \"MRR@10\": np.mean(mrrs),\n",
    "            \"Coverage\": validator.coverage(preds),\n",
    "        }\n",
    "        results.append(metrics)\n",
    "\n",
    "    df = pl.DataFrame(results)\n",
    "    if verbose:\n",
    "        print(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624119e0",
   "metadata": {},
   "source": [
    "#### Функция векторизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5fb4e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextVectorizer:\n",
    "    def __init__(self, max_features: int = 200, stop_words: str = 'english'):  # Уменьшено до 200\n",
    "        self.vectorizer = TfidfVectorizer(max_features=max_features, stop_words=stop_words)\n",
    "        self.item_vectors = None\n",
    "        self.item_ids = None\n",
    "\n",
    "    def fit(self, metadata: pl.DataFrame):\n",
    "        logger.info(\"Начало TF-IDF векторизации...\")\n",
    "        logger.info(f\"Использование памяти: {psutil.virtual_memory().percent}%\")\n",
    "        \n",
    "        # Подготовка текстовых данных\n",
    "        metadata = metadata.with_columns(\n",
    "            pl.col(\"description\").fill_null(\"\") + \" \" + \n",
    "            pl.col(\"tags\").list.join(\" \").fill_null(\"\")\n",
    "        )\n",
    "        corpus = metadata[\"description\"].to_list()\n",
    "        self.item_ids = metadata[\"item_id\"].to_list()\n",
    "\n",
    "        # Векторизация\n",
    "        self.item_vectors = self.vectorizer.fit_transform(corpus)\n",
    "        logger.info(f\"TF-IDF векторизация завершена. Размер матрицы: {self.item_vectors.shape}\")\n",
    "        logger.info(f\"Использование памяти после векторизации: {psutil.virtual_memory().percent}%\")\n",
    "\n",
    "    def save(self, path: str):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "            joblib.dump({\n",
    "                'vectorizer': self.vectorizer,\n",
    "                'item_vectors': self.item_vectors,\n",
    "                'item_ids': self.item_ids\n",
    "            }, path)\n",
    "            logger.info(f\"Векторизатор сохранен в {path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка при сохранении векторизатора: {e}\")\n",
    "            raise\n",
    "\n",
    "    def load(self, path: str):\n",
    "        try:\n",
    "            data = joblib.load(path)\n",
    "            self.vectorizer = data['vectorizer']\n",
    "            self.item_vectors = data['item_vectors']\n",
    "            self.item_ids = data['item_ids']\n",
    "            logger.info(f\"Векторизатор загружен из {path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка при загрузке векторизатора: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289159ad",
   "metadata": {},
   "source": [
    "#### Базовый класс для загрузки моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04fc2c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender(ABC):\n",
    "    def __init__(self, model_path: str = None):\n",
    "        self.model = None\n",
    "        self.model_path = model_path\n",
    "        if model_path and os.path.exists(model_path):\n",
    "            self.load_model()\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, train: pl.DataFrame, vectorizer: TextVectorizer = None):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, user_ids: List[int], k: int = 10) -> Dict[int, List[int]]:\n",
    "        pass\n",
    "\n",
    "    def save_model(self):\n",
    "        if self.model_path:\n",
    "            try:\n",
    "                os.makedirs(os.path.dirname(self.model_path), exist_ok=True)\n",
    "                joblib.dump(self.model, self.model_path)\n",
    "                logger.info(f\"Модель сохранена в {self.model_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Ошибка при сохранении модели в {self.model_path}: {e}\")\n",
    "                raise\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model_path and os.path.exists(self.model_path):\n",
    "            try:\n",
    "                self.model = joblib.load(self.model_path)\n",
    "                logger.info(f\"Модель загружена из {self.model_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Ошибка при загрузке модели из {self.model_path}: {e}\")\n",
    "                raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bce9b2",
   "metadata": {},
   "source": [
    "### Использование контентных методов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1969c198",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a631dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatBoostRecommender(Recommender):\n",
    "    def __init__(self, model_path: str = \"../models/catboost/catboost_recommender.pkl\", force_retrain: bool = False):\n",
    "        super().__init__(model_path)\n",
    "        self.vectorizer = None\n",
    "        self.item_vectors = None\n",
    "        self.item_ids = None\n",
    "        self.force_retrain = force_retrain\n",
    "\n",
    "    def fit(self, train: pl.DataFrame, vectorizer: TextVectorizer = None):\n",
    "        if not isinstance(vectorizer, TextVectorizer):\n",
    "            logger.error(\"Аргумент 'vectorizer' должен быть экземпляром TextVectorizer\")\n",
    "            raise TypeError(\"Аргумент 'vectorizer' должен быть экземпляром TextVectorizer\")\n",
    "        if self.model_path and os.path.exists(self.model_path) and not self.force_retrain:\n",
    "            self.load_model()\n",
    "            return\n",
    "\n",
    "        logger.info(\"Начало обучения CatBoostRecommender...\")\n",
    "        logger.info(f\"Использование памяти: {psutil.virtual_memory().percent}%\")\n",
    "\n",
    "        # Используем общий векторизатор\n",
    "        self.vectorizer = vectorizer.vectorizer\n",
    "        self.item_vectors = vectorizer.item_vectors\n",
    "        self.item_ids = vectorizer.item_ids\n",
    "\n",
    "        # Путь для сохранения промежуточных данных\n",
    "        data_path = \"../models/catboost/catboost_data.pkl\"\n",
    "        if os.path.exists(data_path) and not self.force_retrain:\n",
    "            logger.info(\"Загрузка сохраненных данных для CatBoost...\")\n",
    "            data = joblib.load(data_path)\n",
    "            X, y = data['X'], data['y']\n",
    "        else:\n",
    "            # Подготовка данных для CatBoost с пакетной записью на диск\n",
    "            X, y = [], []\n",
    "            user_items = train.group_by(\"user_id\").agg(pl.col(\"item_id\")).to_pandas()\n",
    "            item_id_to_idx = {item_id: idx for idx, item_id in enumerate(self.item_ids)}\n",
    "            batch_size = 1000  # Обрабатываем по 1000 пользователей за раз\n",
    "            batch_count = 0\n",
    "\n",
    "            for i in tqdm(range(0, len(user_items), batch_size), desc=\"Подготовка данных для CatBoost\"):\n",
    "                batch = user_items[i:i+batch_size]\n",
    "                batch_X, batch_y = [], []\n",
    "                for _, row in batch.iterrows():\n",
    "                    user_id = row[\"user_id\"]\n",
    "                    pos_items = set(row[\"item_id\"])\n",
    "                    neg_items = list(set(self.item_ids) - pos_items)[:min(len(pos_items), 5)]  # Уменьшено до 5\n",
    "\n",
    "                    # Используем разреженные матрицы для экономии памяти\n",
    "                    valid_pos_items = [item for item in pos_items if item in item_id_to_idx]\n",
    "                    user_vector = np.mean(\n",
    "                        [self.item_vectors[item_id_to_idx[item]].toarray()[0] for item in valid_pos_items],\n",
    "                        axis=0\n",
    "                    ) if valid_pos_items else np.zeros(self.item_vectors.shape[1])\n",
    "\n",
    "                    for item_id in pos_items:\n",
    "                        if item_id in item_id_to_idx:\n",
    "                            item_vector = self.item_vectors[item_id_to_idx[item_id]].toarray()[0]\n",
    "                            batch_X.append(np.concatenate([user_vector, item_vector]))\n",
    "                            batch_y.append(1)\n",
    "\n",
    "                    for item_id in neg_items:\n",
    "                        if item_id in item_id_to_idx:\n",
    "                            item_vector = self.item_vectors[item_id_to_idx[item_id]].toarray()[0]\n",
    "                            batch_X.append(np.concatenate([user_vector, item_vector]))\n",
    "                            batch_y.append(0)\n",
    "\n",
    "                # Сохранение батча на диск\n",
    "                batch_path = f\"../models/catboost/catboost_data_batch_{batch_count}.pkl\"\n",
    "                try:\n",
    "                    os.makedirs(os.path.dirname(batch_path), exist_ok=True)\n",
    "                    joblib.dump({'X': batch_X, 'y': batch_y}, batch_path)\n",
    "                    logger.info(f\"Батч {batch_count} сохранен в {batch_path}\")\n",
    "                    batch_count += 1\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Ошибка при сохранении батча {batch_count}: {e}\")\n",
    "                    raise\n",
    "                # Очистка памяти\n",
    "                batch_X, batch_y = [], []\n",
    "                gc.collect()\n",
    "\n",
    "            # Объединение батчей\n",
    "            X, y = [], []\n",
    "            for i in range(batch_count):\n",
    "                batch_data = joblib.load(f\"../models/catboost/catboost_data_batch_{i}.pkl\")\n",
    "                X.extend(batch_data['X'])\n",
    "                y.extend(batch_data['y'])\n",
    "                os.remove(f\"../models/catboost/catboost_data_batch_{i}.pkl\")  # Удаление временного файла\n",
    "            try:\n",
    "                os.makedirs(os.path.dirname(data_path), exist_ok=True)\n",
    "                joblib.dump({'X': X, 'y': y}, data_path)\n",
    "                logger.info(f\"Данные CatBoost сохранены в {data_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Ошибка при сохранении данных CatBoost: {e}\")\n",
    "                raise\n",
    "\n",
    "        logger.info(f\"Создано {len(X)} пар пользователь-книга\")\n",
    "        logger.info(f\"Использование памяти после подготовки данных: {psutil.virtual_memory().percent}%\")\n",
    "\n",
    "        # Обучение CatBoost\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        train_pool = Pool(X_train, y_train)\n",
    "        val_pool = Pool(X_val, y_val)\n",
    "\n",
    "        self.model = CatBoostClassifier(iterations=30, depth=6, learning_rate=0.1, thread_count=-1, verbose=10)\n",
    "        self.model.fit(train_pool, eval_set=val_pool)\n",
    "        logger.info(\"Обучение CatBoost завершено\")\n",
    "\n",
    "        self.save_model()\n",
    "\n",
    "    def predict(self, user_ids: List[int], k: int = 10, batch_size: int = 1000) -> Dict[int, List[int]]:\n",
    "        predictions = {}\n",
    "        item_id_to_idx = {item_id: idx for idx, item_id in enumerate(self.item_ids)}\n",
    "\n",
    "        for i in tqdm(range(0, len(user_ids), batch_size), desc=\"Predicting with CatBoost\"):\n",
    "            batch_users = user_ids[i:i+batch_size]\n",
    "            for user_id in batch_users:\n",
    "                user_items = train.filter(pl.col(\"user_id\") == user_id)[\"item_id\"].to_list()\n",
    "                user_vector = np.mean(\n",
    "                    [self.item_vectors[item_id_to_idx[item]].toarray()[0] for item in user_items if item in item_id_to_idx],\n",
    "                    axis=0\n",
    "                ) if user_items else np.zeros(self.item_vectors.shape[1])\n",
    "\n",
    "                X_pred = []\n",
    "                pred_items = []\n",
    "                for item_id in self.item_ids:\n",
    "                    item_vector = self.item_vectors[item_id_to_idx[item_id]].toarray()[0]\n",
    "                    X_pred.append(np.concatenate([user_vector, item_vector]))\n",
    "                    pred_items.append(item_id)\n",
    "\n",
    "                scores = self.model.predict_proba(X_pred)[:, 1]\n",
    "                top_k_indices = np.argsort(scores)[::-1][:k]\n",
    "                predictions[user_id] = [pred_items[idx] for idx in top_k_indices]\n",
    "            gc.collect()  # Очистка памяти после батча\n",
    "        return predictions\n",
    "\n",
    "    def save_model(self):\n",
    "        if self.model_path:\n",
    "            try:\n",
    "                os.makedirs(os.path.dirname(self.model_path), exist_ok=True)\n",
    "                joblib.dump({\n",
    "                    'model': self.model,\n",
    "                    'vectorizer': self.vectorizer,\n",
    "                    'item_vectors': self.item_vectors,\n",
    "                    'item_ids': self.item_ids\n",
    "                }, self.model_path)\n",
    "                logger.info(f\"Модель сохранена в {self.model_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Ошибка при сохранении CatBoostRecommender: {e}\")\n",
    "                raise\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model_path and os.path.exists(self.model_path):\n",
    "            try:\n",
    "                data = joblib.load(self.model_path)\n",
    "                self.model = data['model']\n",
    "                self.vectorizer = data['vectorizer']\n",
    "                self.item_vectors = data['item_vectors']\n",
    "                self.item_ids = data['item_ids']\n",
    "                logger.info(f\"Модель CatBoostRecommender загружена из {self.model_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Ошибка при загрузке CatBoostRecommender: {e}\")\n",
    "                raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7140281",
   "metadata": {},
   "source": [
    "### Обучение моделей "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3301c098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 11:25:52,859 - INFO - Векторизатор загружен из ../models/vectorizer/tfidf_vectorizer.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train users: 349719, items: 31300\n",
      "Test users: 185828, items: 27367\n",
      "Cold items: 1775\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train users: {train['user_id'].n_unique()}, items: {len(train_items)}\")\n",
    "print(f\"Test users: {test['user_id'].n_unique()}, items: {len(test_items)}\")\n",
    "print(f\"Cold items: {len(cold_items)}\")\n",
    "user_ids = test[\"user_id\"].unique().to_list()\n",
    "\n",
    "vectorizer = TextVectorizer(max_features=1000)\n",
    "vectorizer_path = \"../models/vectorizer/tfidf_vectorizer.pkl\"\n",
    "if os.path.exists(vectorizer_path):\n",
    "    vectorizer.load(vectorizer_path)\n",
    "else:\n",
    "    vectorizer.fit(books)\n",
    "    vectorizer.save(vectorizer_path)\n",
    "\n",
    "# Инициализируем и обучаем разные модели\n",
    "force_retrain = True  # Переключатель для обучения/загрузки моделей\n",
    "catboost_recommender = CatBoostRecommender(model_path=\"../models/catboost/catboost_recommender.pkl\", force_retrain=force_retrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709672af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 11:25:53,195 - INFO - Используется подвыборка для обучения: 34971 пользователей\n",
      "2025-09-07 11:25:53,229 - INFO - Используется подвыборка для предсказания: 18582 пользователей\n",
      "2025-09-07 11:25:53,362 - INFO - === Обучение и предсказание CatBoostRecommender ===\n",
      "2025-09-07 11:25:53,363 - INFO - Начало обучения CatBoostRecommender...\n",
      "2025-09-07 11:25:53,363 - INFO - Использование памяти: 77.2%\n",
      "Подготовка данных для CatBoost:   0%|          | 0/35 [00:00<?, ?it/s]2025-09-07 11:25:56,144 - INFO - Батч 0 сохранен в ../models/catboost/catboost_data_batch_0.pkl\n",
      "Подготовка данных для CatBoost:   3%|▎         | 1/35 [00:02<01:35,  2.80s/it]2025-09-07 11:25:59,228 - INFO - Батч 1 сохранен в ../models/catboost/catboost_data_batch_1.pkl\n",
      "Подготовка данных для CatBoost:   6%|▌         | 2/35 [00:05<01:37,  2.97s/it]2025-09-07 11:26:02,027 - INFO - Батч 2 сохранен в ../models/catboost/catboost_data_batch_2.pkl\n",
      "Подготовка данных для CatBoost:   9%|▊         | 3/35 [00:08<01:32,  2.89s/it]2025-09-07 11:26:05,112 - INFO - Батч 3 сохранен в ../models/catboost/catboost_data_batch_3.pkl\n",
      "Подготовка данных для CatBoost:  11%|█▏        | 4/35 [00:11<01:31,  2.97s/it]2025-09-07 11:26:08,206 - INFO - Батч 4 сохранен в ../models/catboost/catboost_data_batch_4.pkl\n",
      "Подготовка данных для CatBoost:  14%|█▍        | 5/35 [00:14<01:30,  3.01s/it]2025-09-07 11:26:11,193 - INFO - Батч 5 сохранен в ../models/catboost/catboost_data_batch_5.pkl\n",
      "Подготовка данных для CatBoost:  17%|█▋        | 6/35 [00:17<01:27,  3.00s/it]2025-09-07 11:26:14,183 - INFO - Батч 6 сохранен в ../models/catboost/catboost_data_batch_6.pkl\n",
      "Подготовка данных для CatBoost:  20%|██        | 7/35 [00:20<01:23,  3.00s/it]2025-09-07 11:26:17,327 - INFO - Батч 7 сохранен в ../models/catboost/catboost_data_batch_7.pkl\n",
      "Подготовка данных для CatBoost:  23%|██▎       | 8/35 [00:23<01:22,  3.05s/it]2025-09-07 11:26:20,507 - INFO - Батч 8 сохранен в ../models/catboost/catboost_data_batch_8.pkl\n",
      "Подготовка данных для CatBoost:  26%|██▌       | 9/35 [00:27<01:20,  3.09s/it]2025-09-07 11:26:23,341 - INFO - Батч 9 сохранен в ../models/catboost/catboost_data_batch_9.pkl\n",
      "Подготовка данных для CatBoost:  29%|██▊       | 10/35 [00:29<01:15,  3.01s/it]2025-09-07 11:26:26,522 - INFO - Батч 10 сохранен в ../models/catboost/catboost_data_batch_10.pkl\n",
      "Подготовка данных для CatBoost:  31%|███▏      | 11/35 [00:33<01:13,  3.06s/it]2025-09-07 11:26:29,405 - INFO - Батч 11 сохранен в ../models/catboost/catboost_data_batch_11.pkl\n",
      "Подготовка данных для CatBoost:  34%|███▍      | 12/35 [00:36<01:09,  3.01s/it]2025-09-07 11:26:32,585 - INFO - Батч 12 сохранен в ../models/catboost/catboost_data_batch_12.pkl\n",
      "Подготовка данных для CatBoost:  37%|███▋      | 13/35 [00:39<01:07,  3.06s/it]2025-09-07 11:26:35,552 - INFO - Батч 13 сохранен в ../models/catboost/catboost_data_batch_13.pkl\n",
      "Подготовка данных для CatBoost:  40%|████      | 14/35 [00:42<01:03,  3.03s/it]2025-09-07 11:26:38,331 - INFO - Батч 14 сохранен в ../models/catboost/catboost_data_batch_14.pkl\n",
      "Подготовка данных для CatBoost:  43%|████▎     | 15/35 [00:44<00:59,  2.96s/it]2025-09-07 11:26:41,663 - INFO - Батч 15 сохранен в ../models/catboost/catboost_data_batch_15.pkl\n",
      "Подготовка данных для CatBoost:  46%|████▌     | 16/35 [00:48<00:58,  3.07s/it]2025-09-07 11:26:44,577 - INFO - Батч 16 сохранен в ../models/catboost/catboost_data_batch_16.pkl\n",
      "Подготовка данных для CatBoost:  49%|████▊     | 17/35 [00:51<00:54,  3.02s/it]2025-09-07 11:26:47,679 - INFO - Батч 17 сохранен в ../models/catboost/catboost_data_batch_17.pkl\n",
      "Подготовка данных для CatBoost:  51%|█████▏    | 18/35 [00:54<00:51,  3.05s/it]2025-09-07 11:26:50,706 - INFO - Батч 18 сохранен в ../models/catboost/catboost_data_batch_18.pkl\n",
      "Подготовка данных для CatBoost:  54%|█████▍    | 19/35 [00:57<00:48,  3.04s/it]2025-09-07 11:26:53,624 - INFO - Батч 19 сохранен в ../models/catboost/catboost_data_batch_19.pkl\n",
      "Подготовка данных для CatBoost:  57%|█████▋    | 20/35 [01:00<00:45,  3.00s/it]2025-09-07 11:26:56,453 - INFO - Батч 20 сохранен в ../models/catboost/catboost_data_batch_20.pkl\n",
      "Подготовка данных для CatBoost:  60%|██████    | 21/35 [01:03<00:41,  2.95s/it]2025-09-07 11:26:59,356 - INFO - Батч 21 сохранен в ../models/catboost/catboost_data_batch_21.pkl\n",
      "Подготовка данных для CatBoost:  63%|██████▎   | 22/35 [01:06<00:38,  2.94s/it]2025-09-07 11:27:02,342 - INFO - Батч 22 сохранен в ../models/catboost/catboost_data_batch_22.pkl\n",
      "Подготовка данных для CatBoost:  66%|██████▌   | 23/35 [01:08<00:35,  2.95s/it]2025-09-07 11:27:05,225 - INFO - Батч 23 сохранен в ../models/catboost/catboost_data_batch_23.pkl\n",
      "Подготовка данных для CatBoost:  69%|██████▊   | 24/35 [01:11<00:32,  2.93s/it]2025-09-07 11:27:08,198 - INFO - Батч 24 сохранен в ../models/catboost/catboost_data_batch_24.pkl\n",
      "Подготовка данных для CatBoost:  71%|███████▏  | 25/35 [01:14<00:29,  2.94s/it]2025-09-07 11:27:11,209 - INFO - Батч 25 сохранен в ../models/catboost/catboost_data_batch_25.pkl\n",
      "Подготовка данных для CatBoost:  74%|███████▍  | 26/35 [01:17<00:26,  2.96s/it]2025-09-07 11:27:14,285 - INFO - Батч 26 сохранен в ../models/catboost/catboost_data_batch_26.pkl\n",
      "Подготовка данных для CatBoost:  77%|███████▋  | 27/35 [01:20<00:23,  3.00s/it]2025-09-07 11:27:17,072 - INFO - Батч 27 сохранен в ../models/catboost/catboost_data_batch_27.pkl\n",
      "Подготовка данных для CatBoost:  80%|████████  | 28/35 [01:23<00:20,  2.93s/it]2025-09-07 11:27:20,445 - INFO - Батч 28 сохранен в ../models/catboost/catboost_data_batch_28.pkl\n",
      "Подготовка данных для CatBoost:  83%|████████▎ | 29/35 [01:27<00:18,  3.07s/it]2025-09-07 11:27:23,210 - INFO - Батч 29 сохранен в ../models/catboost/catboost_data_batch_29.pkl\n",
      "Подготовка данных для CatBoost:  86%|████████▌ | 30/35 [01:29<00:14,  2.98s/it]2025-09-07 11:27:26,290 - INFO - Батч 30 сохранен в ../models/catboost/catboost_data_batch_30.pkl\n",
      "Подготовка данных для CatBoost:  89%|████████▊ | 31/35 [01:32<00:12,  3.01s/it]2025-09-07 11:27:29,514 - INFO - Батч 31 сохранен в ../models/catboost/catboost_data_batch_31.pkl\n",
      "Подготовка данных для CatBoost:  91%|█████████▏| 32/35 [01:36<00:09,  3.07s/it]2025-09-07 11:27:32,536 - INFO - Батч 32 сохранен в ../models/catboost/catboost_data_batch_32.pkl\n",
      "Подготовка данных для CatBoost:  94%|█████████▍| 33/35 [01:39<00:06,  3.06s/it]2025-09-07 11:27:35,365 - INFO - Батч 33 сохранен в ../models/catboost/catboost_data_batch_33.pkl\n",
      "Подготовка данных для CatBoost:  97%|█████████▋| 34/35 [01:42<00:02,  2.99s/it]2025-09-07 11:27:38,091 - INFO - Батч 34 сохранен в ../models/catboost/catboost_data_batch_34.pkl\n",
      "Подготовка данных для CatBoost: 100%|██████████| 35/35 [01:44<00:00,  2.99s/it]\n",
      "2025-09-07 11:31:04,220 - INFO - Данные CatBoost сохранены в ../models/catboost/catboost_data.pkl\n",
      "2025-09-07 11:31:04,229 - INFO - Создано 1339640 пар пользователь-книга\n",
      "2025-09-07 11:31:04,231 - INFO - Использование памяти после подготовки данных: 78.2%\n"
     ]
    }
   ],
   "source": [
    "# Подвыборка пользователей для обучения \n",
    "sample_users = train[\"user_id\"].unique().sample(fraction=0.1, seed=42).to_list()\n",
    "train_sample = train.filter(pl.col(\"user_id\").is_in(sample_users))\n",
    "logger.info(f\"Используется подвыборка для обучения: {len(sample_users)} пользователей\")\n",
    "\n",
    "# Подвыборка пользователей для предсказания \n",
    "user_ids = test[\"user_id\"].unique().sample(fraction=0.1, seed=42).to_list()\n",
    "logger.info(f\"Используется подвыборка для предсказания: {len(user_ids)} пользователей\")\n",
    "\n",
    "# Ограничение книг для предсказания (топ-1000 популярных)\n",
    "popular_items = train.group_by(\"item_id\").agg(pl.len()).sort(\"len\", descending=True).head(1000)[\"item_id\"].to_list()\n",
    "logger.info(\"=== Обучение и предсказание CatBoostRecommender ===\")\n",
    "pred_catboost_path = \"../models/catboost/pred_catboost.pkl\"\n",
    "if os.path.exists(pred_catboost_path):\n",
    "    logger.info(\"Загрузка сохраненных предсказаний CatBoostRecommender...\")\n",
    "    pred_catboost = joblib.load(pred_catboost_path)\n",
    "else:\n",
    "    try:\n",
    "        catboost_recommender = CatBoostRecommender(model_path=\"../models/catboost/catboost_recommender.pkl\", force_retrain=True)\n",
    "        catboost_recommender.fit(train_sample, vectorizer)\n",
    "        pred_catboost = catboost_recommender.predict(user_ids, item_subset=popular_items, batch_size=500)\n",
    "        logger.info(\"CatBoostRecommender обучен и предсказания получены\")\n",
    "        joblib.dump(pred_catboost, pred_catboost_path)\n",
    "        logger.info(f\"Предсказания CatBoostRecommender сохранены в {pred_catboost_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Ошибка при обучении/предсказании CatBoostRecommender: {e}\")\n",
    "        raise\n",
    "\n",
    "models = {\n",
    "    \"CatBoost\": pred_catboost,\n",
    "}\n",
    "\n",
    "print(\"\\nРекомендации моделей:\")\n",
    "train_df = show_predictions(models, train, n=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970f4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nСтатистика по метрикам:\")\n",
    "validator = JointValidator(train, test, cold_items)\n",
    "metrics_df = val_predictions(models, test, validator, k=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nСтатистика по метрикам (SplitValidator):\")\n",
    "split_validator = SplitValidator(train, test, cold_items)\n",
    "metrics_df_split = val_predictions(models, test, split_validator, k=10, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
