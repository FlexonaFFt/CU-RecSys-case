{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25497418",
   "metadata": {},
   "source": [
    "# Контентные методы "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688bfe8",
   "metadata": {},
   "source": [
    "### Базовые операции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2afc3887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os \n",
    "import logging\n",
    "import joblib\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, List\n",
    "from collections import defaultdict, Counter \n",
    "\n",
    "import lightgbm as lgb\n",
    "from scipy.sparse import vstack, hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "os.makedirs('../models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aecb716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сразу загружу данные\n",
    "train = pl.read_parquet(\"../../data/train.pq\")\n",
    "test = pl.read_parquet(\"../../data/test.pq\")\n",
    "books = pl.read_parquet(\"../../data/books.pq\")\n",
    "\n",
    "train_items = set(train[\"item_id\"].unique())\n",
    "test_items = set(test[\"item_id\"].unique())\n",
    "cold_items = test_items - train_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc86f568",
   "metadata": {},
   "source": [
    "#### Метрики оценивания моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b46c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validator(ABC):\n",
    "    def __init__(self, train: pd.DataFrame, test: pd.DataFrame, cold_items: set = None):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.cold_items = cold_items or set()\n",
    "\n",
    "    @abstractmethod\n",
    "    def evaluate(self, predictions: Dict[int, List[int]]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        predictions: dict user_id -> list of recommended item_ids\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def recall_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        return len(set(y_true) & set(y_pred[:k])) / len(set(y_true)) if y_true else 0.0\n",
    "\n",
    "    def precision_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        return len(set(y_true) & set(y_pred[:k])) / k if y_true else 0.0\n",
    "\n",
    "    def hitrate_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        return 1.0 if len(set(y_true) & set(y_pred[:k])) > 0 else 0.0\n",
    "\n",
    "    def ndcg_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        dcg = 0.0\n",
    "        for i, item in enumerate(y_pred[:k]):\n",
    "            if item in y_true:\n",
    "                dcg += 1 / np.log2(i + 2)\n",
    "        idcg = sum(1 / np.log2(i + 2) for i in range(min(len(y_true), k)))\n",
    "        return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    def mrr_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        for i, item in enumerate(y_pred[:k]):\n",
    "            if item in y_true:\n",
    "                return 1 / (i + 1)\n",
    "        return 0.0\n",
    "\n",
    "    def coverage(self, predictions: Dict[int, List[int]]) -> float:\n",
    "        all_pred_items = set(item for recs in predictions.values() for item in recs)\n",
    "        all_train_items = set(self.train[\"item_id\"].unique())\n",
    "        return len(all_pred_items) / len(all_train_items)\n",
    "\n",
    "    @staticmethod\n",
    "    def print_metrics(metrics: Dict[str, float]):\n",
    "        print(\"\\n=== Evaluation Results ===\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"{key:<15}: {value:.4f}\")\n",
    "        print(\"==========================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7e5b41",
   "metadata": {},
   "source": [
    "Стоит разделить валидацию на две версии, для сравнения. Моя гипотеза заключается в том, что совместная валидация warm и cold может быть не совсем честной. Например, если в тесте 90% warm и 10% cold, то Recall@10 в среднем будет определяться warm-айтемами. Модель может полностью «забыть» про cold items, но в отчёте всё равно будут хорошие цифры. Это вводит в заблуждение: кажется, что модель универсальная, хотя на самом деле cold-start не решён."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada31206",
   "metadata": {},
   "source": [
    "#### Блок совместной валидации (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8fd76c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointValidator(Validator):\n",
    "    def __init__(self, train: pl.DataFrame, test: pl.DataFrame, cold_items: set = None):\n",
    "        super().__init__(train, test, cold_items)\n",
    "        self.user2items = (\n",
    "            test.group_by(\"user_id\").agg(pl.col(\"item_id\")).to_dict(as_series=False)\n",
    "        )\n",
    "        self.user2items = dict(zip(self.user2items[\"user_id\"], self.user2items[\"item_id\"]))\n",
    "\n",
    "    def evaluate(self, predictions: Dict[int, List[int]]) -> Dict[str, float]:\n",
    "        recalls, precisions, hits, ndcgs, mrrs = [], [], [], [], []\n",
    "        for user_id, y_pred in predictions.items():\n",
    "            y_true = self.user2items.get(user_id, [])\n",
    "            recalls.append(self.recall_at_k(y_true, y_pred))\n",
    "            precisions.append(self.precision_at_k(y_true, y_pred))\n",
    "            hits.append(self.hitrate_at_k(y_true, y_pred))\n",
    "            ndcgs.append(self.ndcg_at_k(y_true, y_pred))\n",
    "            mrrs.append(self.mrr_at_k(y_true, y_pred))\n",
    "        results = {\n",
    "            \"Recall@10\": np.mean(recalls),\n",
    "            \"Precision@10\": np.mean(precisions),\n",
    "            \"HitRate@10\": np.mean(hits),\n",
    "            \"NDCG@10\": np.mean(ndcgs),\n",
    "            \"MRR@10\": np.mean(mrrs),\n",
    "            \"Coverage\": self.coverage(predictions),\n",
    "        }\n",
    "        self.print_metrics(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19c9d8c",
   "metadata": {},
   "source": [
    "#### Разделенная валидация (cold vs warm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4fcf8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitValidator(Validator):\n",
    "    def __init__(self, train: pl.DataFrame, test: pl.DataFrame, cold_items: set = None):\n",
    "        super().__init__(train, test, cold_items)\n",
    "        self.user2items = (\n",
    "            test.group_by(\"user_id\").agg(pl.col(\"item_id\")).to_dict(as_series=False)\n",
    "        )\n",
    "        self.user2items = dict(zip(self.user2items[\"user_id\"], self.user2items[\"item_id\"]))\n",
    "\n",
    "    def evaluate(self, predictions: Dict[int, List[int]]) -> Dict[str, float]:\n",
    "        results = {}\n",
    "        for subset in [\"cold\", \"warm\"]:\n",
    "            recalls, precisions, hits, ndcgs, mrrs = [], [], [], [], []\n",
    "            for user_id, y_pred in predictions.items():\n",
    "                y_true = self.user2items.get(user_id, [])\n",
    "                if not y_true:\n",
    "                    continue\n",
    "                if subset == \"cold\":\n",
    "                    y_true = [i for i in y_true if i in self.cold_items]\n",
    "                elif subset == \"warm\":\n",
    "                    y_true = [i for i in y_true if i not in self.cold_items]\n",
    "                if not y_true:\n",
    "                    continue\n",
    "                recalls.append(self.recall_at_k(y_true, y_pred))\n",
    "                precisions.append(self.precision_at_k(y_true, y_pred))\n",
    "                hits.append(self.hitrate_at_k(y_true, y_pred))\n",
    "                ndcgs.append(self.ndcg_at_k(y_true, y_pred))\n",
    "                mrrs.append(self.mrr_at_k(y_true, y_pred))\n",
    "            results[f\"Recall@10_{subset}\"] = np.mean(recalls) if recalls else 0.0\n",
    "            results[f\"Precision@10_{subset}\"] = np.mean(precisions) if precisions else 0.0\n",
    "            results[f\"HitRate@10_{subset}\"] = np.mean(hits) if hits else 0.0\n",
    "            results[f\"NDCG@10_{subset}\"] = np.mean(ndcgs) if ndcgs else 0.0\n",
    "            results[f\"MRR@10_{subset}\"] = np.mean(mrrs) if mrrs else 0.0\n",
    "        results[\"Coverage\"] = self.coverage(predictions)\n",
    "        self.print_metrics(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5488f3",
   "metadata": {},
   "source": [
    "#### Вспомогательные функции для удобного представления результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37d934e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shorten_list(lst, max_len=10):\n",
    "    \"\"\"Обрезает длинные списки для красивого вывода\"\"\"\n",
    "    if lst is None:\n",
    "        return []\n",
    "    return lst[:max_len] if len(lst) > max_len else lst\n",
    "\n",
    "def show_predictions(models: dict, data: pl.DataFrame, n=5, verbose=True, is_val=False):\n",
    "    df = data.sample(n).select([\"user_id\", \"item_id\"])\n",
    "    if is_val:\n",
    "        df = df.rename({\"item_id\": \"true_items\"})\n",
    "\n",
    "    # добавляем предсказания\n",
    "    for name, preds in models.items():\n",
    "        df = df.with_columns(\n",
    "            pl.col(\"user_id\").map_elements(\n",
    "                lambda u: _shorten_list(preds.get(u, [])), \n",
    "                return_dtype=pl.List(pl.Int64)\n",
    "            ).alias(name)\n",
    "        )\n",
    "\n",
    "    if verbose:\n",
    "        print(df.shape)\n",
    "        print(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def val_predictions(models: dict, val: pl.DataFrame, validator: Validator, k: int = 10, verbose: bool = True):\n",
    "    results = []\n",
    "    user2items = (\n",
    "        val.group_by(\"user_id\").agg(pl.col(\"item_id\")).to_dict(as_series=False)\n",
    "    )\n",
    "    user2items = dict(zip(user2items[\"user_id\"], user2items[\"item_id\"]))\n",
    "\n",
    "    for model_name, preds in models.items():\n",
    "        recalls, precisions, hits, ndcgs, mrrs = [], [], [], [], []\n",
    "        for u, y_true in user2items.items():\n",
    "            y_pred = preds.get(u, [])\n",
    "            recalls.append(validator.recall_at_k(y_true, y_pred, k))\n",
    "            precisions.append(validator.precision_at_k(y_true, y_pred, k))\n",
    "            hits.append(validator.hitrate_at_k(y_true, y_pred, k))\n",
    "            ndcgs.append(validator.ndcg_at_k(y_true, y_pred, k))\n",
    "            mrrs.append(validator.mrr_at_k(y_true, y_pred, k))\n",
    "        metrics = {\n",
    "            \"model\": model_name,\n",
    "            \"Recall@10\": np.mean(recalls),\n",
    "            \"Precision@10\": np.mean(precisions),\n",
    "            \"HitRate@10\": np.mean(hits),\n",
    "            \"NDCG@10\": np.mean(ndcgs),\n",
    "            \"MRR@10\": np.mean(mrrs),\n",
    "            \"Coverage\": validator.coverage(preds),\n",
    "        }\n",
    "        results.append(metrics)\n",
    "\n",
    "    df = pl.DataFrame(results)\n",
    "    if verbose:\n",
    "        print(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624119e0",
   "metadata": {},
   "source": [
    "#### Функция векторизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5fb4e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextVectorizer:\n",
    "    def __init__(self, max_features: int = 200, stop_words: str = 'english'):  # Уменьшено до 200\n",
    "        self.vectorizer = TfidfVectorizer(max_features=max_features, stop_words=stop_words)\n",
    "        self.item_vectors = None\n",
    "        self.item_ids = None\n",
    "\n",
    "    def fit(self, metadata: pl.DataFrame):\n",
    "        logger.info(\"Начало TF-IDF векторизации...\")\n",
    "        logger.info(f\"Использование памяти: {psutil.virtual_memory().percent}%\")\n",
    "        \n",
    "        # Подготовка текстовых данных\n",
    "        metadata = metadata.with_columns(\n",
    "            pl.col(\"description\").fill_null(\"\") + \" \" + \n",
    "            pl.col(\"tags\").list.join(\" \").fill_null(\"\")\n",
    "        )\n",
    "        corpus = metadata[\"description\"].to_list()\n",
    "        self.item_ids = metadata[\"item_id\"].to_list()\n",
    "\n",
    "        # Векторизация\n",
    "        self.item_vectors = self.vectorizer.fit_transform(corpus)\n",
    "        logger.info(f\"TF-IDF векторизация завершена. Размер матрицы: {self.item_vectors.shape}\")\n",
    "        logger.info(f\"Использование памяти после векторизации: {psutil.virtual_memory().percent}%\")\n",
    "\n",
    "    def save(self, path: str):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "            joblib.dump({\n",
    "                'vectorizer': self.vectorizer,\n",
    "                'item_vectors': self.item_vectors,\n",
    "                'item_ids': self.item_ids\n",
    "            }, path)\n",
    "            logger.info(f\"Векторизатор сохранен в {path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка при сохранении векторизатора: {e}\")\n",
    "            raise\n",
    "\n",
    "    def load(self, path: str):\n",
    "        try:\n",
    "            data = joblib.load(path)\n",
    "            self.vectorizer = data['vectorizer']\n",
    "            self.item_vectors = data['item_vectors']\n",
    "            self.item_ids = data['item_ids']\n",
    "            logger.info(f\"Векторизатор загружен из {path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка при загрузке векторизатора: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289159ad",
   "metadata": {},
   "source": [
    "#### Базовый класс для загрузки моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04fc2c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender(ABC):\n",
    "    def __init__(self, model_path: str = None):\n",
    "        self.model = None\n",
    "        self.model_path = model_path\n",
    "        if model_path and os.path.exists(model_path):\n",
    "            self.load_model()\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, train: pl.DataFrame, vectorizer: TextVectorizer = None):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, user_ids: List[int], k: int = 10) -> Dict[int, List[int]]:\n",
    "        pass\n",
    "\n",
    "    def save_model(self):\n",
    "        if self.model_path:\n",
    "            try:\n",
    "                os.makedirs(os.path.dirname(self.model_path), exist_ok=True)\n",
    "                joblib.dump(self.model, self.model_path)\n",
    "                logger.info(f\"Модель сохранена в {self.model_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Ошибка при сохранении модели в {self.model_path}: {e}\")\n",
    "                raise\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model_path and os.path.exists(self.model_path):\n",
    "            try:\n",
    "                self.model = joblib.load(self.model_path)\n",
    "                logger.info(f\"Модель загружена из {self.model_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Ошибка при загрузке модели из {self.model_path}: {e}\")\n",
    "                raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bce9b2",
   "metadata": {},
   "source": [
    "### Использование контентных методов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a572906",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35f2c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGBMRecommender(Recommender):\n",
    "    def __init__(self, model_path: str = \"../models/lightgbm/lightgbm_recommender.pkl\", force_retrain: bool = False):\n",
    "        super().__init__(model_path)\n",
    "        self.vectorizer = None\n",
    "        self.item_vectors = None\n",
    "        self.item_ids = None\n",
    "        self.force_retrain = force_retrain\n",
    "\n",
    "    def fit(self, train: pl.DataFrame, vectorizer: TextVectorizer = None):\n",
    "        if not isinstance(vectorizer, TextVectorizer):\n",
    "            logger.error(\"Аргумент 'vectorizer' должен быть экземпляром TextVectorizer\")\n",
    "            raise TypeError(\"Аргумент 'vectorizer' должен быть экземпляром TextVectorizer\")\n",
    "        if self.model_path and os.path.exists(self.model_path) and not self.force_retrain:\n",
    "            self.load_model()\n",
    "            return\n",
    "\n",
    "        logger.info(\"Начало обучения LightGBMRecommender...\")\n",
    "        logger.info(f\"Использование памяти: {psutil.virtual_memory().percent}%\")\n",
    "\n",
    "        self.vectorizer = vectorizer.vectorizer\n",
    "        self.item_vectors = vectorizer.item_vectors\n",
    "        self.item_ids = vectorizer.item_ids\n",
    "\n",
    "        data_path = \"../models/lightgbm/lightgbm_data.pkl\"\n",
    "        if os.path.exists(data_path) and not self.force_retrain:\n",
    "            logger.info(\"Загрузка сохраненных данных для LightGBM...\")\n",
    "            data = joblib.load(data_path)\n",
    "            X, y = data['X'], data['y']\n",
    "        else:\n",
    "            X, y = [], []\n",
    "            user_items = train.group_by(\"user_id\").agg(pl.col(\"item_id\")).to_pandas()\n",
    "            item_id_to_idx = {item_id: idx for idx, item_id in enumerate(self.item_ids)}\n",
    "            batch_size = 500\n",
    "            batch_count = 0\n",
    "\n",
    "            for i in tqdm(range(0, len(user_items), batch_size), desc=\"Подготовка данных для LightGBM\"):\n",
    "                batch = user_items[i:i+batch_size]\n",
    "                batch_X, batch_y = [], []\n",
    "                for _, row in batch.iterrows():\n",
    "                    user_id = row[\"user_id\"]\n",
    "                    pos_items = set(row[\"item_id\"])\n",
    "                    neg_items = list(set(self.item_ids) - pos_items)[:min(len(pos_items), 5)]\n",
    "\n",
    "                    valid_pos_items = [item for item in pos_items if item in item_id_to_idx]\n",
    "                    if not valid_pos_items:\n",
    "                        logger.debug(f\"Пользователь {user_id} не имеет валидных элементов, пропускаем\")\n",
    "                        continue\n",
    "\n",
    "                    user_vector = vstack([self.item_vectors[item_id_to_idx[item]] for item in valid_pos_items]).mean(axis=0)\n",
    "                    logger.debug(f\"Пользователь {user_id}: {len(valid_pos_items)} валидных элементов\")\n",
    "\n",
    "                    for item_id in pos_items:\n",
    "                        if item_id in item_id_to_idx:\n",
    "                            item_vector = self.item_vectors[item_id_to_idx[item_id]]\n",
    "                            batch_X.append(hstack([user_vector, item_vector]))\n",
    "                            batch_y.append(1)\n",
    "\n",
    "                    for item_id in neg_items:\n",
    "                        if item_id in item_id_to_idx:\n",
    "                            item_vector = self.item_vectors[item_id_to_idx[item_id]]\n",
    "                            batch_X.append(hstack([user_vector, item_vector]))\n",
    "                            batch_y.append(0)\n",
    "\n",
    "                if not batch_X:\n",
    "                    logger.warning(f\"Батч {batch_count} пустой, пропускаем\")\n",
    "                    continue\n",
    "\n",
    "                batch_path = f\"../models/lightgbm/lightgbm_data_batch_{batch_count}.pkl\"\n",
    "                try:\n",
    "                    os.makedirs(os.path.dirname(batch_path), exist_ok=True)\n",
    "                    joblib.dump({'X': batch_X, 'y': batch_y}, batch_path)\n",
    "                    logger.info(f\"Батч {batch_count} сохранен в {batch_path}, размер: {len(batch_X)} пар\")\n",
    "                    batch_count += 1\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Ошибка при сохранении батча {batch_count}: {e}\")\n",
    "                    raise\n",
    "                batch_X, batch_y = [], []\n",
    "                gc.collect()\n",
    "\n",
    "            if batch_count == 0:\n",
    "                logger.error(\"Не создано ни одного батча данных. Проверьте данные train и item_ids.\")\n",
    "                raise ValueError(\"Не удалось создать данные для обучения LightGBM: пустой датасет\")\n",
    "\n",
    "            X, y = [], []\n",
    "            for i in range(batch_count):\n",
    "                batch_data = joblib.load(f\"../models/lightgbm/lightgbm_data_batch_{i}.pkl\")\n",
    "                X.extend(batch_data['X'])\n",
    "                y.extend(batch_data['y'])\n",
    "                os.remove(f\"../models/lightgbm/lightgbm_data_batch_{i}.pkl\")\n",
    "            try:\n",
    "                os.makedirs(os.path.dirname(data_path), exist_ok=True)\n",
    "                joblib.dump({'X': X, 'y': y}, data_path)\n",
    "                logger.info(f\"Данные LightGBM сохранены в {data_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Ошибка при сохранении данных LightGBM: {e}\")\n",
    "                raise\n",
    "\n",
    "        if not X:\n",
    "            logger.error(\"Датасет X пустой. Проверьте наличие валидных элементов в train и item_ids.\")\n",
    "            raise ValueError(\"Пустой датасет X для LightGBM\")\n",
    "\n",
    "        logger.info(f\"Создано {len(X)} пар пользователь-книга\")\n",
    "        logger.info(f\"Использование памяти после подготовки данных: {psutil.virtual_memory().percent}%\")\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        if not X_train:\n",
    "            logger.error(\"X_train пустой после разделения. Проверьте данные.\")\n",
    "            raise ValueError(\"Пустой X_train для LightGBM\")\n",
    "\n",
    "        # Convert to single sparse matrix\n",
    "        X_train_matrix = vstack(X_train)\n",
    "        X_val_matrix = vstack(X_val)\n",
    "        logger.info(f\"X_train shape: {X_train_matrix.shape}, X_val shape: {X_val_matrix.shape}\")\n",
    "\n",
    "        train_data = lgb.Dataset(X_train_matrix, label=y_train)\n",
    "        val_data = lgb.Dataset(X_val_matrix, label=y_val, reference=train_data)\n",
    "\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'num_threads': -1\n",
    "        }\n",
    "        self.model = lgb.train(params, train_data, valid_sets=[val_data], num_boost_round=30)\n",
    "        logger.info(\"Обучение LightGBM завершено\")\n",
    "        self.save_model()\n",
    "\n",
    "    def predict(self, user_ids: List[int], k: int = 10, item_subset: List[int] = None, batch_size: int = 500) -> Dict[int, List[int]]:\n",
    "        predictions = {}\n",
    "        item_id_to_idx = {item_id: idx for idx, item_id in enumerate(self.item_ids)}\n",
    "        pred_items_subset = item_subset if item_subset is not None else self.item_ids\n",
    "\n",
    "        for i in tqdm(range(0, len(user_ids), batch_size), desc=\"Predicting with LightGBM\"):\n",
    "            batch_users = user_ids[i:i+batch_size]\n",
    "            for user_id in batch_users:\n",
    "                user_items = train.filter(pl.col(\"user_id\") == user_id)[\"item_id\"].to_list()\n",
    "                valid_items = [item for item in user_items if item in item_id_to_idx]\n",
    "                user_vector = vstack([self.item_vectors[item_id_to_idx[item]] for item in valid_items]).mean(axis=0) if valid_items else np.zeros((1, self.item_vectors.shape[1]))\n",
    "\n",
    "                X_pred = []\n",
    "                pred_items = []\n",
    "                for item_id in pred_items_subset:\n",
    "                    if item_id in item_id_to_idx:\n",
    "                        item_vector = self.item_vectors[item_id_to_idx[item_id]]\n",
    "                        X_pred.append(hstack([user_vector, item_vector]))\n",
    "                        pred_items.append(item_id)\n",
    "\n",
    "                if not X_pred:\n",
    "                    logger.warning(f\"Пустой X_pred для пользователя {user_id}, пропускаем\")\n",
    "                    predictions[user_id] = []\n",
    "                    continue\n",
    "\n",
    "                scores = self.model.predict(vstack(X_pred))\n",
    "                top_k_indices = np.argsort(scores)[::-1][:k]\n",
    "                predictions[user_id] = [pred_items[idx] for idx in top_k_indices]\n",
    "            gc.collect()\n",
    "        return predictions\n",
    "\n",
    "    def save_model(self):\n",
    "        if self.model_path:\n",
    "            try:\n",
    "                os.makedirs(os.path.dirname(self.model_path), exist_ok=True)\n",
    "                joblib.dump({\n",
    "                    'model': self.model,\n",
    "                    'vectorizer': self.vectorizer,\n",
    "                    'item_vectors': self.item_vectors,\n",
    "                    'item_ids': self.item_ids\n",
    "                }, self.model_path)\n",
    "                logger.info(f\"Модель сохранена в {self.model_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Ошибка при сохранении LightGBMRecommender: {e}\")\n",
    "                raise\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model_path and os.path.exists(self.model_path):\n",
    "            try:\n",
    "                data = joblib.load(self.model_path)\n",
    "                self.model = data['model']\n",
    "                self.vectorizer = data['vectorizer']\n",
    "                self.item_vectors = data['item_vectors']\n",
    "                self.item_ids = data['item_ids']\n",
    "                logger.info(f\"Модель LightGBMRecommender загружена из {self.model_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Ошибка при загрузке LightGBMRecommender: {e}\")\n",
    "                raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7140281",
   "metadata": {},
   "source": [
    "### Обучение моделей "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3301c098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 11:53:17,346 - INFO - Векторизатор загружен из ../models/vectorizer/tfidf_vectorizer.pkl\n",
      "2025-09-07 11:53:17,374 - INFO - Модель LightGBMRecommender загружена из ../models/lightgbm/lightgbm_recommender.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train users: 349719, items: 31300\n",
      "Test users: 185828, items: 27367\n",
      "Cold items: 1775\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train users: {train['user_id'].n_unique()}, items: {len(train_items)}\")\n",
    "print(f\"Test users: {test['user_id'].n_unique()}, items: {len(test_items)}\")\n",
    "print(f\"Cold items: {len(cold_items)}\")\n",
    "user_ids = test[\"user_id\"].unique().to_list()\n",
    "\n",
    "vectorizer = TextVectorizer(max_features=1000)\n",
    "vectorizer_path = \"../models/vectorizer/tfidf_vectorizer.pkl\"\n",
    "if os.path.exists(vectorizer_path):\n",
    "    vectorizer.load(vectorizer_path)\n",
    "else:\n",
    "    vectorizer.fit(books)\n",
    "    vectorizer.save(vectorizer_path)\n",
    "\n",
    "# Инициализируем и обучаем разные модели\n",
    "force_retrain = True  # Переключатель для обучения/загрузки моделей\n",
    "lightgbm_recommender = LightGBMRecommender(model_path=\"../models/lightgbm/lightgbm_recommender.pkl\", force_retrain=force_retrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "709672af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 11:53:17,704 - INFO - Используется подвыборка для обучения: 34971 пользователей\n",
      "2025-09-07 11:53:17,738 - INFO - Используется подвыборка для предсказания: 1858 пользователей\n",
      "2025-09-07 11:53:17,818 - INFO - === Обучение и предсказание LightGBMRecommender ===\n",
      "2025-09-07 11:53:17,839 - INFO - Модель LightGBMRecommender загружена из ../models/lightgbm/lightgbm_recommender.pkl\n",
      "2025-09-07 11:53:17,839 - INFO - Начало обучения LightGBMRecommender...\n",
      "2025-09-07 11:53:17,840 - INFO - Использование памяти: 62.4%\n",
      "Подготовка данных для LightGBM:   0%|          | 0/70 [00:00<?, ?it/s]2025-09-07 11:53:22,083 - INFO - Батч 0 сохранен в ../models/lightgbm/lightgbm_data_batch_0.pkl, размер: 16734 пар\n",
      "Подготовка данных для LightGBM:   1%|▏         | 1/70 [00:04<04:54,  4.26s/it]2025-09-07 11:53:26,417 - INFO - Батч 1 сохранен в ../models/lightgbm/lightgbm_data_batch_1.pkl, размер: 17329 пар\n",
      "Подготовка данных для LightGBM:   3%|▎         | 2/70 [00:08<04:52,  4.30s/it]2025-09-07 11:53:31,065 - INFO - Батч 2 сохранен в ../models/lightgbm/lightgbm_data_batch_2.pkl, размер: 18919 пар\n",
      "Подготовка данных для LightGBM:   4%|▍         | 3/70 [00:13<04:58,  4.46s/it]2025-09-07 11:53:35,761 - INFO - Батч 3 сохранен в ../models/lightgbm/lightgbm_data_batch_3.pkl, размер: 18947 пар\n",
      "Подготовка данных для LightGBM:   6%|▌         | 4/70 [00:17<05:00,  4.55s/it]2025-09-07 11:53:40,356 - INFO - Батч 4 сохранен в ../models/lightgbm/lightgbm_data_batch_4.pkl, размер: 18533 пар\n",
      "Подготовка данных для LightGBM:   7%|▋         | 5/70 [00:22<04:56,  4.57s/it]2025-09-07 11:53:44,797 - INFO - Батч 5 сохранен в ../models/lightgbm/lightgbm_data_batch_5.pkl, размер: 18014 пар\n",
      "Подготовка данных для LightGBM:   9%|▊         | 6/70 [00:26<04:49,  4.52s/it]2025-09-07 11:53:49,509 - INFO - Батч 6 сохранен в ../models/lightgbm/lightgbm_data_batch_6.pkl, размер: 19082 пар\n",
      "Подготовка данных для LightGBM:  10%|█         | 7/70 [00:31<04:48,  4.59s/it]2025-09-07 11:53:54,737 - INFO - Батч 7 сохранен в ../models/lightgbm/lightgbm_data_batch_7.pkl, размер: 21476 пар\n",
      "Подготовка данных для LightGBM:  11%|█▏        | 8/70 [00:36<04:57,  4.79s/it]2025-09-07 11:53:59,172 - INFO - Батч 8 сохранен в ../models/lightgbm/lightgbm_data_batch_8.pkl, размер: 17843 пар\n",
      "Подготовка данных для LightGBM:  13%|█▎        | 9/70 [00:41<04:45,  4.68s/it]2025-09-07 11:54:04,001 - INFO - Батч 9 сохранен в ../models/lightgbm/lightgbm_data_batch_9.pkl, размер: 19550 пар\n",
      "Подготовка данных для LightGBM:  14%|█▍        | 10/70 [00:46<04:43,  4.73s/it]2025-09-07 11:54:08,203 - INFO - Батч 10 сохранен в ../models/lightgbm/lightgbm_data_batch_10.pkl, размер: 17144 пар\n",
      "Подготовка данных для LightGBM:  16%|█▌        | 11/70 [00:50<04:29,  4.56s/it]2025-09-07 11:54:12,779 - INFO - Батч 11 сохранен в ../models/lightgbm/lightgbm_data_batch_11.pkl, размер: 18659 пар\n",
      "Подготовка данных для LightGBM:  17%|█▋        | 12/70 [00:54<04:24,  4.57s/it]2025-09-07 11:54:18,112 - INFO - Батч 12 сохранен в ../models/lightgbm/lightgbm_data_batch_12.pkl, размер: 21701 пар\n",
      "Подготовка данных для LightGBM:  19%|█▊        | 13/70 [01:00<04:33,  4.80s/it]2025-09-07 11:54:23,232 - INFO - Батч 13 сохранен в ../models/lightgbm/lightgbm_data_batch_13.pkl, размер: 20787 пар\n",
      "Подготовка данных для LightGBM:  20%|██        | 14/70 [01:05<04:34,  4.90s/it]2025-09-07 11:54:28,742 - INFO - Батч 14 сохранен в ../models/lightgbm/lightgbm_data_batch_14.pkl, размер: 22520 пар\n",
      "Подготовка данных для LightGBM:  21%|██▏       | 15/70 [01:10<04:39,  5.08s/it]2025-09-07 11:54:33,313 - INFO - Батч 15 сохранен в ../models/lightgbm/lightgbm_data_batch_15.pkl, размер: 18347 пар\n",
      "Подготовка данных для LightGBM:  23%|██▎       | 16/70 [01:15<04:26,  4.93s/it]2025-09-07 11:54:37,659 - INFO - Батч 16 сохранен в ../models/lightgbm/lightgbm_data_batch_16.pkl, размер: 17533 пар\n",
      "Подготовка данных для LightGBM:  24%|██▍       | 17/70 [01:19<04:11,  4.75s/it]2025-09-07 11:54:43,259 - INFO - Батч 17 сохранен в ../models/lightgbm/lightgbm_data_batch_17.pkl, размер: 22962 пар\n",
      "Подготовка данных для LightGBM:  26%|██▌       | 18/70 [01:25<04:20,  5.01s/it]2025-09-07 11:54:47,835 - INFO - Батч 18 сохранен в ../models/lightgbm/lightgbm_data_batch_18.pkl, размер: 18247 пар\n",
      "Подготовка данных для LightGBM:  27%|██▋       | 19/70 [01:30<04:08,  4.88s/it]2025-09-07 11:54:52,853 - INFO - Батч 19 сохранен в ../models/lightgbm/lightgbm_data_batch_19.pkl, размер: 20303 пар\n",
      "Подготовка данных для LightGBM:  29%|██▊       | 20/70 [01:35<04:06,  4.92s/it]2025-09-07 11:54:57,353 - INFO - Батч 20 сохранен в ../models/lightgbm/lightgbm_data_batch_20.pkl, размер: 18188 пар\n",
      "Подготовка данных для LightGBM:  30%|███       | 21/70 [01:39<03:54,  4.79s/it]2025-09-07 11:55:01,847 - INFO - Батч 21 сохранен в ../models/lightgbm/lightgbm_data_batch_21.pkl, размер: 18151 пар\n",
      "Подготовка данных для LightGBM:  31%|███▏      | 22/70 [01:44<03:45,  4.70s/it]2025-09-07 11:55:06,982 - INFO - Батч 22 сохранен в ../models/lightgbm/lightgbm_data_batch_22.pkl, размер: 20950 пар\n",
      "Подготовка данных для LightGBM:  33%|███▎      | 23/70 [01:49<03:47,  4.83s/it]2025-09-07 11:55:11,370 - INFO - Батч 23 сохранен в ../models/lightgbm/lightgbm_data_batch_23.pkl, размер: 17696 пар\n",
      "Подготовка данных для LightGBM:  34%|███▍      | 24/70 [01:53<03:36,  4.70s/it]2025-09-07 11:55:17,317 - INFO - Батч 24 сохранен в ../models/lightgbm/lightgbm_data_batch_24.pkl, размер: 24416 пар\n",
      "Подготовка данных для LightGBM:  36%|███▌      | 25/70 [01:59<03:48,  5.07s/it]2025-09-07 11:55:22,051 - INFO - Батч 25 сохранен в ../models/lightgbm/lightgbm_data_batch_25.pkl, размер: 18607 пар\n",
      "Подготовка данных для LightGBM:  37%|███▋      | 26/70 [02:04<03:38,  4.97s/it]2025-09-07 11:55:26,639 - INFO - Батч 26 сохранен в ../models/lightgbm/lightgbm_data_batch_26.pkl, размер: 18530 пар\n",
      "Подготовка данных для LightGBM:  39%|███▊      | 27/70 [02:08<03:28,  4.86s/it]2025-09-07 11:55:32,126 - INFO - Батч 27 сохранен в ../models/lightgbm/lightgbm_data_batch_27.pkl, размер: 22603 пар\n",
      "Подготовка данных для LightGBM:  40%|████      | 28/70 [02:14<03:31,  5.05s/it]2025-09-07 11:55:37,203 - INFO - Батч 28 сохранен в ../models/lightgbm/lightgbm_data_batch_28.pkl, размер: 20575 пар\n",
      "Подготовка данных для LightGBM:  41%|████▏     | 29/70 [02:19<03:27,  5.05s/it]2025-09-07 11:55:41,991 - INFO - Батч 29 сохранен в ../models/lightgbm/lightgbm_data_batch_29.pkl, размер: 19393 пар\n",
      "Подготовка данных для LightGBM:  43%|████▎     | 30/70 [02:24<03:18,  4.97s/it]2025-09-07 11:55:46,247 - INFO - Батч 30 сохранен в ../models/lightgbm/lightgbm_data_batch_30.pkl, размер: 17359 пар\n",
      "Подготовка данных для LightGBM:  44%|████▍     | 31/70 [02:28<03:05,  4.76s/it]2025-09-07 11:55:51,340 - INFO - Батч 31 сохранен в ../models/lightgbm/lightgbm_data_batch_31.pkl, размер: 20864 пар\n",
      "Подготовка данных для LightGBM:  46%|████▌     | 32/70 [02:33<03:04,  4.86s/it]2025-09-07 11:55:56,330 - INFO - Батч 32 сохранен в ../models/lightgbm/lightgbm_data_batch_32.pkl, размер: 20334 пар\n",
      "Подготовка данных для LightGBM:  47%|████▋     | 33/70 [02:38<03:01,  4.90s/it]2025-09-07 11:56:01,450 - INFO - Батч 33 сохранен в ../models/lightgbm/lightgbm_data_batch_33.pkl, размер: 20977 пар\n",
      "Подготовка данных для LightGBM:  49%|████▊     | 34/70 [02:43<02:58,  4.97s/it]2025-09-07 11:56:06,083 - INFO - Батч 34 сохранен в ../models/lightgbm/lightgbm_data_batch_34.pkl, размер: 18703 пар\n",
      "Подготовка данных для LightGBM:  50%|█████     | 35/70 [02:48<02:50,  4.86s/it]2025-09-07 11:56:10,237 - INFO - Батч 35 сохранен в ../models/lightgbm/lightgbm_data_batch_35.pkl, размер: 16980 пар\n",
      "Подготовка данных для LightGBM:  51%|█████▏    | 36/70 [02:52<02:38,  4.65s/it]2025-09-07 11:56:15,593 - INFO - Батч 36 сохранен в ../models/lightgbm/lightgbm_data_batch_36.pkl, размер: 22133 пар\n",
      "Подготовка данных для LightGBM:  53%|█████▎    | 37/70 [02:57<02:40,  4.86s/it]2025-09-07 11:56:19,575 - INFO - Батч 37 сохранен в ../models/lightgbm/lightgbm_data_batch_37.pkl, размер: 16113 пар\n",
      "Подготовка данных для LightGBM:  54%|█████▍    | 38/70 [03:01<02:27,  4.60s/it]2025-09-07 11:56:23,595 - INFO - Батч 38 сохранен в ../models/lightgbm/lightgbm_data_batch_38.pkl, размер: 16350 пар\n",
      "Подготовка данных для LightGBM:  56%|█████▌    | 39/70 [03:05<02:17,  4.42s/it]2025-09-07 11:56:29,113 - INFO - Батч 39 сохранен в ../models/lightgbm/lightgbm_data_batch_39.pkl, размер: 22719 пар\n",
      "Подготовка данных для LightGBM:  57%|█████▋    | 40/70 [03:11<02:22,  4.75s/it]2025-09-07 11:56:33,242 - INFO - Батч 40 сохранен в ../models/lightgbm/lightgbm_data_batch_40.pkl, размер: 16860 пар\n",
      "Подготовка данных для LightGBM:  59%|█████▊    | 41/70 [03:15<02:12,  4.57s/it]2025-09-07 11:56:38,051 - INFO - Батч 41 сохранен в ../models/lightgbm/lightgbm_data_batch_41.pkl, размер: 19591 пар\n",
      "Подготовка данных для LightGBM:  60%|██████    | 42/70 [03:20<02:09,  4.64s/it]2025-09-07 11:56:42,735 - INFO - Батч 42 сохранен в ../models/lightgbm/lightgbm_data_batch_42.pkl, размер: 19063 пар\n",
      "Подготовка данных для LightGBM:  61%|██████▏   | 43/70 [03:24<02:05,  4.65s/it]2025-09-07 11:56:47,391 - INFO - Батч 43 сохранен в ../models/lightgbm/lightgbm_data_batch_43.pkl, размер: 18995 пар\n",
      "Подготовка данных для LightGBM:  63%|██████▎   | 44/70 [03:29<02:00,  4.65s/it]2025-09-07 11:56:52,549 - INFO - Батч 44 сохранен в ../models/lightgbm/lightgbm_data_batch_44.pkl, размер: 20666 пар\n",
      "Подготовка данных для LightGBM:  64%|██████▍   | 45/70 [03:34<02:00,  4.81s/it]2025-09-07 11:56:58,300 - INFO - Батч 45 сохранен в ../models/lightgbm/lightgbm_data_batch_45.pkl, размер: 23528 пар\n",
      "Подготовка данных для LightGBM:  66%|██████▌   | 46/70 [03:40<02:02,  5.09s/it]2025-09-07 11:57:02,186 - INFO - Батч 46 сохранен в ../models/lightgbm/lightgbm_data_batch_46.pkl, размер: 15586 пар\n",
      "Подготовка данных для LightGBM:  67%|██████▋   | 47/70 [03:44<01:48,  4.73s/it]2025-09-07 11:57:07,005 - INFO - Батч 47 сохранен в ../models/lightgbm/lightgbm_data_batch_47.pkl, размер: 19493 пар\n",
      "Подготовка данных для LightGBM:  69%|██████▊   | 48/70 [03:49<01:44,  4.75s/it]2025-09-07 11:57:11,829 - INFO - Батч 48 сохранен в ../models/lightgbm/lightgbm_data_batch_48.pkl, размер: 19511 пар\n",
      "Подготовка данных для LightGBM:  70%|███████   | 49/70 [03:54<01:40,  4.78s/it]2025-09-07 11:57:16,498 - INFO - Батч 49 сохранен в ../models/lightgbm/lightgbm_data_batch_49.pkl, размер: 18939 пар\n",
      "Подготовка данных для LightGBM:  71%|███████▏  | 50/70 [03:58<01:34,  4.74s/it]2025-09-07 11:57:20,980 - INFO - Батч 50 сохранен в ../models/lightgbm/lightgbm_data_batch_50.pkl, размер: 17991 пар\n",
      "Подготовка данных для LightGBM:  73%|███████▎  | 51/70 [04:03<01:28,  4.67s/it]2025-09-07 11:57:25,125 - INFO - Батч 51 сохранен в ../models/lightgbm/lightgbm_data_batch_51.pkl, размер: 16905 пар\n",
      "Подготовка данных для LightGBM:  74%|███████▍  | 52/70 [04:07<01:21,  4.51s/it]2025-09-07 11:57:29,190 - INFO - Батч 52 сохранен в ../models/lightgbm/lightgbm_data_batch_52.pkl, размер: 16543 пар\n",
      "Подготовка данных для LightGBM:  76%|███████▌  | 53/70 [04:11<01:14,  4.38s/it]2025-09-07 11:57:33,676 - INFO - Батч 53 сохранен в ../models/lightgbm/lightgbm_data_batch_53.pkl, размер: 17767 пар\n",
      "Подготовка данных для LightGBM:  77%|███████▋  | 54/70 [04:15<01:10,  4.41s/it]2025-09-07 11:57:38,729 - INFO - Батч 54 сохранен в ../models/lightgbm/lightgbm_data_batch_54.pkl, размер: 20671 пар\n",
      "Подготовка данных для LightGBM:  79%|███████▊  | 55/70 [04:20<01:09,  4.60s/it]2025-09-07 11:57:44,146 - INFO - Батч 55 сохранен в ../models/lightgbm/lightgbm_data_batch_55.pkl, размер: 22135 пар\n",
      "Подготовка данных для LightGBM:  80%|████████  | 56/70 [04:26<01:07,  4.85s/it]2025-09-07 11:57:48,254 - INFO - Батч 56 сохранен в ../models/lightgbm/lightgbm_data_batch_56.pkl, размер: 16766 пар\n",
      "Подготовка данных для LightGBM:  81%|████████▏ | 57/70 [04:30<01:00,  4.62s/it]2025-09-07 11:57:52,539 - INFO - Батч 57 сохранен в ../models/lightgbm/lightgbm_data_batch_57.pkl, размер: 17173 пар\n",
      "Подготовка данных для LightGBM:  83%|████████▎ | 58/70 [04:34<00:54,  4.52s/it]2025-09-07 11:57:57,471 - INFO - Батч 58 сохранен в ../models/lightgbm/lightgbm_data_batch_58.pkl, размер: 20089 пар\n",
      "Подготовка данных для LightGBM:  84%|████████▍ | 59/70 [04:39<00:51,  4.65s/it]2025-09-07 11:58:02,359 - INFO - Батч 59 сохранен в ../models/lightgbm/lightgbm_data_batch_59.pkl, размер: 20085 пар\n",
      "Подготовка данных для LightGBM:  86%|████████▌ | 60/70 [04:44<00:47,  4.72s/it]2025-09-07 11:58:06,948 - INFO - Батч 60 сохранен в ../models/lightgbm/lightgbm_data_batch_60.pkl, размер: 18528 пар\n",
      "Подготовка данных для LightGBM:  87%|████████▋ | 61/70 [04:49<00:42,  4.68s/it]2025-09-07 11:58:12,550 - INFO - Батч 61 сохранен в ../models/lightgbm/lightgbm_data_batch_61.pkl, размер: 23224 пар\n",
      "Подготовка данных для LightGBM:  89%|████████▊ | 62/70 [04:54<00:39,  4.96s/it]2025-09-07 11:58:16,801 - INFO - Батч 62 сохранен в ../models/lightgbm/lightgbm_data_batch_62.pkl, размер: 17077 пар\n",
      "Подготовка данных для LightGBM:  90%|█████████ | 63/70 [04:58<00:33,  4.74s/it]2025-09-07 11:58:21,733 - INFO - Батч 63 сохранен в ../models/lightgbm/lightgbm_data_batch_63.pkl, размер: 20118 пар\n",
      "Подготовка данных для LightGBM:  91%|█████████▏| 64/70 [05:03<00:28,  4.80s/it]2025-09-07 11:58:26,613 - INFO - Батч 64 сохранен в ../models/lightgbm/lightgbm_data_batch_64.pkl, размер: 19823 пар\n",
      "Подготовка данных для LightGBM:  93%|█████████▎| 65/70 [05:08<00:24,  4.82s/it]2025-09-07 11:58:30,767 - INFO - Батч 65 сохранен в ../models/lightgbm/lightgbm_data_batch_65.pkl, размер: 16955 пар\n",
      "Подготовка данных для LightGBM:  94%|█████████▍| 66/70 [05:12<00:18,  4.62s/it]2025-09-07 11:58:34,811 - INFO - Батч 66 сохранен в ../models/lightgbm/lightgbm_data_batch_66.pkl, размер: 16474 пар\n",
      "Подготовка данных для LightGBM:  96%|█████████▌| 67/70 [05:16<00:13,  4.45s/it]2025-09-07 11:58:38,819 - INFO - Батч 67 сохранен в ../models/lightgbm/lightgbm_data_batch_67.pkl, размер: 16155 пар\n",
      "Подготовка данных для LightGBM:  97%|█████████▋| 68/70 [05:20<00:08,  4.32s/it]2025-09-07 11:58:43,165 - INFO - Батч 68 сохранен в ../models/lightgbm/lightgbm_data_batch_68.pkl, размер: 17493 пар\n",
      "Подготовка данных для LightGBM:  99%|█████████▊| 69/70 [05:25<00:04,  4.33s/it]2025-09-07 11:58:47,615 - INFO - Батч 69 сохранен в ../models/lightgbm/lightgbm_data_batch_69.pkl, размер: 17991 пар\n",
      "Подготовка данных для LightGBM: 100%|██████████| 70/70 [05:29<00:00,  4.71s/it]\n",
      "2025-09-07 12:04:47,995 - INFO - Данные LightGBM сохранены в ../models/lightgbm/lightgbm_data.pkl\n",
      "2025-09-07 12:04:48,009 - INFO - Создано 1338466 пар пользователь-книга\n",
      "2025-09-07 12:04:48,012 - INFO - Использование памяти после подготовки данных: 75.6%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     lightgbm_recommender \u001b[38;5;241m=\u001b[39m LightGBMRecommender(model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/lightgbm/lightgbm_recommender.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, force_retrain\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mlightgbm_recommender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     pred_gbm \u001b[38;5;241m=\u001b[39m lightgbm_recommender\u001b[38;5;241m.\u001b[39mpredict(user_ids, item_subset\u001b[38;5;241m=\u001b[39mpopular_items, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m     21\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLightGBMRecommender обучен и предсказания получены\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[31], line 111\u001b[0m, in \u001b[0;36mLightGBMRecommender.fit\u001b[0;34m(self, train, vectorizer)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mПустой X_train для LightGBM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Convert to single sparse matrix\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m X_train_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m X_val_matrix \u001b[38;5;241m=\u001b[39m vstack(X_val)\n\u001b[1;32m    113\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train_matrix\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, X_val shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_val_matrix\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/curecsys/myenv/lib/python3.9/site-packages/scipy/sparse/_construct.py:781\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _block([[b] \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m blocks], \u001b[38;5;28mformat\u001b[39m, dtype)\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 781\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_spmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/curecsys/myenv/lib/python3.9/site-packages/scipy/sparse/_construct.py:979\u001b[0m, in \u001b[0;36m_block\u001b[0;34m(blocks, format, dtype, return_spmatrix)\u001b[0m\n\u001b[1;32m    977\u001b[0m B \u001b[38;5;241m=\u001b[39m blocks[i, j]\n\u001b[1;32m    978\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(nnz, nnz \u001b[38;5;241m+\u001b[39m B\u001b[38;5;241m.\u001b[39mnnz)\n\u001b[0;32m--> 979\u001b[0m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m B\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    980\u001b[0m np\u001b[38;5;241m.\u001b[39madd(B\u001b[38;5;241m.\u001b[39mrow, row_offsets[i], out\u001b[38;5;241m=\u001b[39mrow[idx], dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[1;32m    981\u001b[0m np\u001b[38;5;241m.\u001b[39madd(B\u001b[38;5;241m.\u001b[39mcol, col_offsets[j], out\u001b[38;5;241m=\u001b[39mcol[idx], dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sample_users = train[\"user_id\"].unique().sample(fraction=0.1, seed=42).to_list()\n",
    "train_sample = train.filter(pl.col(\"user_id\").is_in(sample_users))\n",
    "logger.info(f\"Используется подвыборка для обучения: {len(sample_users)} пользователей\")\n",
    "\n",
    "# Подвыборка пользователей для предсказания (10% от всех пользователей в test)\n",
    "user_ids = test[\"user_id\"].unique().sample(fraction=0.01, seed=42).to_list()\n",
    "logger.info(f\"Используется подвыборка для предсказания: {len(user_ids)} пользователей\")\n",
    "\n",
    "# Ограничение книг для предсказания (топ-1000 популярных)\n",
    "popular_items = train.group_by(\"item_id\").agg(pl.len()).sort(\"len\", descending=True).head(1000)[\"item_id\"].to_list()\n",
    "logger.info(\"=== Обучение и предсказание LightGBMRecommender ===\")\n",
    "pred_gbm_path = \"../models/lightgbm/pred_gbm.pkl\"\n",
    "if os.path.exists(pred_gbm_path):\n",
    "    logger.info(\"Загрузка сохраненных предсказаний LightGBMRecommender...\")\n",
    "    pred_gbm = joblib.load(pred_gbm_path)\n",
    "else:\n",
    "    try:\n",
    "        lightgbm_recommender = LightGBMRecommender(model_path=\"../models/lightgbm/lightgbm_recommender.pkl\", force_retrain=True)\n",
    "        lightgbm_recommender.fit(train_sample, vectorizer)\n",
    "        pred_gbm = lightgbm_recommender.predict(user_ids, item_subset=popular_items, batch_size=500)\n",
    "        logger.info(\"LightGBMRecommender обучен и предсказания получены\")\n",
    "        joblib.dump(pred_gbm, pred_gbm_path)\n",
    "        logger.info(f\"Предсказания LightGBMRecommender сохранены в {pred_gbm_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Ошибка при обучении/предсказании LightGBMRecommender: {e}\")\n",
    "        raise\n",
    "\n",
    "models = {\n",
    "    \"LightGBM\": pred_gbm,\n",
    "}\n",
    "\n",
    "\n",
    "print(\"\\nРекомендации моделей:\")\n",
    "train_df = show_predictions(models, train, n=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970f4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nСтатистика по метрикам:\")\n",
    "validator = JointValidator(train, test, cold_items)\n",
    "metrics_df = val_predictions(models, test, validator, k=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nСтатистика по метрикам (SplitValidator):\")\n",
    "split_validator = SplitValidator(train, test, cold_items)\n",
    "metrics_df_split = val_predictions(models, test, split_validator, k=10, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
