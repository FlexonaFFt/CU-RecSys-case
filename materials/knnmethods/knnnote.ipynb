{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9713ced",
   "metadata": {},
   "source": [
    "# Метод ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a7cd139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import pickle \n",
    "import json \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from tqdm import tqdm\n",
    "from annoy import AnnoyIndex\n",
    "from lightfm import LightFM\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, List\n",
    "from collections import defaultdict, Counter \n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ea04ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial train_sample size: (1197143, 5)\n",
      "Initial unique users in train_sample: 218650\n",
      "Initial unique items in train_sample: 24094\n",
      "Users with >= 3 interactions: 107589\n",
      "Items with >= 3 interactions: 16386\n",
      "Train sample size: (1038880, 5)\n",
      "Unique users in train_sample: 107586\n",
      "Unique items in train_sample: 16386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/q1n29k35429d2mnrn_3mbtjr0000gn/T/ipykernel_83049/4159219217.py:21: DeprecationWarning: `is_in` with a collection of the same datatype is ambiguous and deprecated.\n",
      "Please use `implode` to return to previous behavior.\n",
      "\n",
      "See https://github.com/pola-rs/polars/issues/22149 for more information.\n",
      "  train_sample = train_sample.filter(pl.col(\"user_id\").is_in(active_users))\n",
      "/var/folders/7k/q1n29k35429d2mnrn_3mbtjr0000gn/T/ipykernel_83049/4159219217.py:27: DeprecationWarning: `is_in` with a collection of the same datatype is ambiguous and deprecated.\n",
      "Please use `implode` to return to previous behavior.\n",
      "\n",
      "See https://github.com/pola-rs/polars/issues/22149 for more information.\n",
      "  train_sample = train_sample.filter(pl.col(\"item_id\").is_in(popular_items))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common users between train_sample and test: 80816\n",
      "Percentage of test users in train_sample: 43.49%\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "train = pl.read_parquet(\"../../data/train.pq\")\n",
    "test = pl.read_parquet(\"../../data/test.pq\")\n",
    "\n",
    "train_items = set(train[\"item_id\"].unique())\n",
    "test_items = set(test[\"item_id\"].unique())\n",
    "cold_items = test_items - train_items\n",
    "\n",
    "# Уменьшаем выборку до 25%\n",
    "train_sample = train.sample(fraction=0.10, seed=42)\n",
    "\n",
    "# Проверка данных до фильтрации\n",
    "print(f\"Initial train_sample size: {train_sample.shape}\")\n",
    "print(f\"Initial unique users in train_sample: {train_sample['user_id'].n_unique()}\")\n",
    "print(f\"Initial unique items in train_sample: {train_sample['item_id'].n_unique()}\")\n",
    "\n",
    "# Фильтрация пользователей с >= 3 взаимодействиями\n",
    "user_counts = train_sample.group_by(\"user_id\").agg(pl.col(\"item_id\").count().alias(\"count\"))\n",
    "active_users = user_counts.filter(pl.col(\"count\") >= 3)[\"user_id\"]\n",
    "print(f\"Users with >= 3 interactions: {len(active_users)}\")\n",
    "train_sample = train_sample.filter(pl.col(\"user_id\").is_in(active_users))\n",
    "\n",
    "# Фильтрация айтемов с >= 3 взаимодействиями\n",
    "item_counts = train_sample.group_by(\"item_id\").agg(pl.col(\"user_id\").count().alias(\"count\"))\n",
    "popular_items = item_counts.filter(pl.col(\"count\") >= 3)[\"item_id\"]\n",
    "print(f\"Items with >= 3 interactions: {len(popular_items)}\")\n",
    "train_sample = train_sample.filter(pl.col(\"item_id\").is_in(popular_items))\n",
    "\n",
    "# Проверка размеров после фильтрации\n",
    "print(f\"Train sample size: {train_sample.shape}\")\n",
    "print(f\"Unique users in train_sample: {train_sample['user_id'].n_unique()}\")\n",
    "print(f\"Unique items in train_sample: {train_sample['item_id'].n_unique()}\")\n",
    "\n",
    "# Проверка, что train_sample не пустой\n",
    "if train_sample.shape[0] == 0:\n",
    "    print(\"ERROR: train_sample is empty after filtering. Relaxing constraints...\")\n",
    "    train_sample = train.sample(fraction=0.25, seed=42)  # Без фильтрации\n",
    "    print(f\"Reset train_sample size: {train_sample.shape}\")\n",
    "\n",
    "# Проверка пересечения пользователей\n",
    "train_users = set(train_sample[\"user_id\"].unique())\n",
    "test_users = set(test[\"user_id\"].unique())\n",
    "common_users = train_users.intersection(test_users)\n",
    "print(f\"Common users between train_sample and test: {len(common_users)}\")\n",
    "print(f\"Percentage of test users in train_sample: {len(common_users) / len(test_users) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a5282",
   "metadata": {},
   "source": [
    "### Метрики оценивания моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc75e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validator(ABC):\n",
    "    def __init__(self, train: pd.DataFrame, test: pd.DataFrame, cold_items: set = None):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.cold_items = cold_items or set()\n",
    "\n",
    "    @abstractmethod\n",
    "    def evaluate(self, predictions: Dict[int, List[int]]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        predictions: dict user_id -> list of recommended item_ids\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def recall_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        return len(set(y_true) & set(y_pred[:k])) / len(set(y_true)) if y_true else 0.0\n",
    "\n",
    "    def precision_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        return len(set(y_true) & set(y_pred[:k])) / k if y_true else 0.0\n",
    "\n",
    "    def hitrate_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        return 1.0 if len(set(y_true) & set(y_pred[:k])) > 0 else 0.0\n",
    "\n",
    "    def ndcg_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        dcg = 0.0\n",
    "        for i, item in enumerate(y_pred[:k]):\n",
    "            if item in y_true:\n",
    "                dcg += 1 / np.log2(i + 2)\n",
    "        idcg = sum(1 / np.log2(i + 2) for i in range(min(len(y_true), k)))\n",
    "        return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    def mrr_at_k(self, y_true: List[int], y_pred: List[int], k: int = 10) -> float:\n",
    "        for i, item in enumerate(y_pred[:k]):\n",
    "            if item in y_true:\n",
    "                return 1 / (i + 1)\n",
    "        return 0.0\n",
    "\n",
    "    def coverage(self, predictions: Dict[int, List[int]]) -> float:\n",
    "        all_pred_items = set(item for recs in predictions.values() for item in recs)\n",
    "        all_train_items = set(self.train[\"item_id\"].unique())\n",
    "        return len(all_pred_items) / len(all_train_items)\n",
    "\n",
    "    @staticmethod\n",
    "    def print_metrics(metrics: Dict[str, float]):\n",
    "        print(\"\\n=== Evaluation Results ===\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"{key:<15}: {value:.4f}\")\n",
    "        print(\"==========================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01662f85",
   "metadata": {},
   "source": [
    "Стоит разделить валидацию на две версии, для сравнения. Моя гипотеза заключается в том, что совместная валидация warm и cold может быть не совсем честной. Например, если в тесте 90% warm и 10% cold, то Recall@10 в среднем будет определяться warm-айтемами. Модель может полностью «забыть» про cold items, но в отчёте всё равно будут хорошие цифры. Это вводит в заблуждение: кажется, что модель универсальная, хотя на самом деле cold-start не решён."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f7d849",
   "metadata": {},
   "source": [
    "#### Блок совместной валидации (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64a70b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointValidator(Validator):\n",
    "    def __init__(self, train: pl.DataFrame, test: pl.DataFrame, cold_items: set = None):\n",
    "        super().__init__(train, test, cold_items)\n",
    "        self.user2items = (\n",
    "            test.group_by(\"user_id\").agg(pl.col(\"item_id\")).to_dict(as_series=False)\n",
    "        )\n",
    "        self.user2items = dict(zip(self.user2items[\"user_id\"], self.user2items[\"item_id\"]))\n",
    "\n",
    "    def evaluate(self, predictions: Dict[int, List[int]]) -> Dict[str, float]:\n",
    "        recalls, precisions, hits, ndcgs, mrrs = [], [], [], [], []\n",
    "        for user_id, y_pred in predictions.items():\n",
    "            y_true = self.user2items.get(user_id, [])\n",
    "            recalls.append(self.recall_at_k(y_true, y_pred))\n",
    "            precisions.append(self.precision_at_k(y_true, y_pred))\n",
    "            hits.append(self.hitrate_at_k(y_true, y_pred))\n",
    "            ndcgs.append(self.ndcg_at_k(y_true, y_pred))\n",
    "            mrrs.append(self.mrr_at_k(y_true, y_pred))\n",
    "        results = {\n",
    "            \"Recall@10\": np.mean(recalls),\n",
    "            \"Precision@10\": np.mean(precisions),\n",
    "            \"HitRate@10\": np.mean(hits),\n",
    "            \"NDCG@10\": np.mean(ndcgs),\n",
    "            \"MRR@10\": np.mean(mrrs),\n",
    "            \"Coverage\": self.coverage(predictions),\n",
    "        }\n",
    "        self.print_metrics(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fbe954",
   "metadata": {},
   "source": [
    "#### Разделенная валидация (cold vs warm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fceeeaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitValidator(Validator):\n",
    "    def __init__(self, train: pl.DataFrame, test: pl.DataFrame, cold_items: set = None):\n",
    "        super().__init__(train, test, cold_items)\n",
    "        self.user2items = (\n",
    "            test.group_by(\"user_id\").agg(pl.col(\"item_id\")).to_dict(as_series=False)\n",
    "        )\n",
    "        self.user2items = dict(zip(self.user2items[\"user_id\"], self.user2items[\"item_id\"]))\n",
    "\n",
    "    def evaluate(self, predictions: Dict[int, List[int]]) -> Dict[str, float]:\n",
    "        results = {}\n",
    "        for subset in [\"cold\", \"warm\"]:\n",
    "            recalls, precisions, hits, ndcgs, mrrs = [], [], [], [], []\n",
    "            for user_id, y_pred in predictions.items():\n",
    "                y_true = self.user2items.get(user_id, [])\n",
    "                if not y_true:\n",
    "                    continue\n",
    "                if subset == \"cold\":\n",
    "                    y_true = [i for i in y_true if i in self.cold_items]\n",
    "                elif subset == \"warm\":\n",
    "                    y_true = [i for i in y_true if i not in self.cold_items]\n",
    "                if not y_true:\n",
    "                    continue\n",
    "                recalls.append(self.recall_at_k(y_true, y_pred))\n",
    "                precisions.append(self.precision_at_k(y_true, y_pred))\n",
    "                hits.append(self.hitrate_at_k(y_true, y_pred))\n",
    "                ndcgs.append(self.ndcg_at_k(y_true, y_pred))\n",
    "                mrrs.append(self.mrr_at_k(y_true, y_pred))\n",
    "            results[f\"Recall@10_{subset}\"] = np.mean(recalls) if recalls else 0.0\n",
    "            results[f\"Precision@10_{subset}\"] = np.mean(precisions) if precisions else 0.0\n",
    "            results[f\"HitRate@10_{subset}\"] = np.mean(hits) if hits else 0.0\n",
    "            results[f\"NDCG@10_{subset}\"] = np.mean(ndcgs) if ndcgs else 0.0\n",
    "            results[f\"MRR@10_{subset}\"] = np.mean(mrrs) if mrrs else 0.0\n",
    "        results[\"Coverage\"] = self.coverage(predictions)\n",
    "        self.print_metrics(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b15366b",
   "metadata": {},
   "source": [
    "### Функции алгоритмов KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4843a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRecommender(ABC):\n",
    "    @abstractmethod\n",
    "    def fit(self, data: pl.DataFrame):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, users: List[int], k: int = 10) -> Dict[int, List[int]]:\n",
    "        pass\n",
    "\n",
    "    def save_predictions(self, predictions: Dict[int, List[int]], filename: str):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(predictions, f)\n",
    "        print(f\"Predictions saved to {filename} (pickle format)\")\n",
    "\n",
    "        with open(filename.replace('.pkl', '.json'), 'w') as f:\n",
    "            json.dump(predictions, f, indent=4)\n",
    "        print(f\"Predictions also saved to {filename.replace('.pkl', '.json')} (JSON format)\")\n",
    "\n",
    "    def load_predictions(self, filename: str) -> Dict[int, List[int]]:\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "285ebca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserKNN(BaseRecommender):\n",
    "    def __init__(self, n_neighbors=20, n_trees=10):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.n_trees = n_trees\n",
    "        self.user_index = None\n",
    "        self.user_item_matrix = None\n",
    "        self.user_id_map = None\n",
    "        self.item_id_map = None\n",
    "\n",
    "    def fit(self, data: pl.DataFrame):\n",
    "        unique_users = data['user_id'].unique().to_list()\n",
    "        unique_items = data['item_id'].unique().to_list()\n",
    "        self.user_id_map = {uid: idx for idx, uid in enumerate(unique_users)}\n",
    "        self.item_id_map = {iid: idx for idx, iid in enumerate(unique_items)}\n",
    "        print(f\"Unique users: {len(unique_users)}, Unique items: {len(unique_items)}\")\n",
    "\n",
    "        rows = data['user_id'].map_elements(lambda u: self.user_id_map.get(u, -1), return_dtype=pl.Int32).to_numpy()\n",
    "        cols = data['item_id'].map_elements(lambda i: self.item_id_map.get(i, -1), return_dtype=pl.Int32).to_numpy()\n",
    "        valid_mask = (rows != -1) & (cols != -1)\n",
    "        rows, cols = rows[valid_mask], cols[valid_mask]\n",
    "        vals = np.ones(len(rows))\n",
    "        self.user_item_matrix = csr_matrix((vals, (rows, cols)), shape=(len(unique_users), len(unique_items)))\n",
    "        print(f\"User-item matrix shape: {self.user_item_matrix.shape}\")\n",
    "        print(f\"User-item matrix memory usage: {self.user_item_matrix.data.nbytes / 1024**2:.2f} MB\")\n",
    "\n",
    "        n_features = len(unique_items)\n",
    "        self.user_index = AnnoyIndex(n_features, 'angular')\n",
    "        for user_idx in tqdm(range(len(unique_users)), desc=\"Building Annoy index for users\"):\n",
    "            user_vector = self.user_item_matrix[user_idx].toarray().flatten()\n",
    "            self.user_index.add_item(user_idx, user_vector)\n",
    "        self.user_index.build(self.n_trees)\n",
    "        print(\"Annoy index for users built.\")\n",
    "        gc.collect()\n",
    "\n",
    "    def predict(self, users: List[int], k: int = 10) -> Dict[int, List[int]]:\n",
    "        global popular_items\n",
    "        predictions = {}\n",
    "        reverse_item_map = {v: k for k, v in self.item_id_map.items()}\n",
    "        for user_id in tqdm(users, desc=\"Predicting with UserKNN (Annoy)\"):\n",
    "            if user_id not in self.user_id_map:\n",
    "                predictions[user_id] = popular_items[:k]\n",
    "                continue\n",
    "            user_idx = self.user_id_map[user_id]\n",
    "            similar_users, distances = self.user_index.get_nns_by_item(user_idx, self.n_neighbors + 1, include_distances=True)\n",
    "            similar_users = similar_users[1:]\n",
    "            distances = distances[1:]\n",
    "            item_scores = defaultdict(float)\n",
    "            for sim_idx, dist in zip(similar_users, distances):\n",
    "                sim_score = 1 - dist / 2\n",
    "                user_items = self.user_item_matrix[sim_idx].indices\n",
    "                for item_idx in user_items:\n",
    "                    item_scores[item_idx] += sim_score\n",
    "            user_known_items = set(self.user_item_matrix[user_idx].indices)\n",
    "            top_items = sorted(item_scores.items(), key=lambda x: -x[1])[:k]\n",
    "            # Для отладки: закомментировать фильтрацию\n",
    "            # top_items = [item_idx for item_idx, _ in top_items if item_idx not in user_known_items]\n",
    "            predictions[user_id] = [reverse_item_map[item_idx] for item_idx, _ in top_items] if top_items else popular_items[:k]\n",
    "            if len(predictions[user_id]) == 0 and user_id == users[0]:\n",
    "                print(f\"Debug for user {user_id}: item_scores len: {len(item_scores)}, known_items len: {len(user_known_items)}, top_items before filter: {len(sorted(item_scores.items(), key=lambda x: -x[1])[:k])}\")\n",
    "        gc.collect()\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "306bde8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemKNN(BaseRecommender):\n",
    "    def __init__(self, n_neighbors=20, n_trees=10):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.n_trees = n_trees\n",
    "        self.item_index = None\n",
    "        self.user_item_matrix = None\n",
    "        self.user_id_map = None\n",
    "        self.item_id_map = None\n",
    "\n",
    "    def fit(self, data: pl.DataFrame):\n",
    "        unique_users = data['user_id'].unique().to_list()\n",
    "        unique_items = data['item_id'].unique().to_list()\n",
    "        self.user_id_map = {uid: idx for idx, uid in enumerate(unique_users)}\n",
    "        self.item_id_map = {iid: idx for idx, iid in enumerate(unique_items)}\n",
    "        print(f\"Unique users: {len(unique_users)}, Unique items: {len(unique_items)}\")\n",
    "\n",
    "        rows = data['user_id'].map_elements(lambda u: self.user_id_map.get(u, -1), return_dtype=pl.Int32).to_numpy()\n",
    "        cols = data['item_id'].map_elements(lambda i: self.item_id_map.get(i, -1), return_dtype=pl.Int32).to_numpy()\n",
    "        valid_mask = (rows != -1) & (cols != -1)\n",
    "        rows, cols = rows[valid_mask], cols[valid_mask]\n",
    "        vals = np.ones(len(rows))\n",
    "        self.user_item_matrix = csr_matrix((vals, (rows, cols)), shape=(len(unique_users), len(unique_items)))\n",
    "        print(f\"User-item matrix shape: {self.user_item_matrix.shape}\")\n",
    "        print(f\"User-item matrix memory usage: {self.user_item_matrix.data.nbytes / 1024**2:.2f} MB\")\n",
    "\n",
    "        item_user_matrix = self.user_item_matrix.T\n",
    "        n_features = item_user_matrix.shape[1]\n",
    "        self.item_index = AnnoyIndex(n_features, 'angular')\n",
    "        for item_idx in tqdm(range(len(unique_items)), desc=\"Building Annoy index for items\"):\n",
    "            item_vector = item_user_matrix[item_idx].toarray().flatten()\n",
    "            self.item_index.add_item(item_idx, item_vector)\n",
    "        self.item_index.build(self.n_trees)\n",
    "        print(\"Annoy index for items built.\")\n",
    "        gc.collect()\n",
    "\n",
    "    def predict(self, users: List[int], k: int = 10) -> Dict[int, List[int]]:\n",
    "        global popular_items\n",
    "        predictions = {}\n",
    "        reverse_item_map = {v: k for k, v in self.item_id_map.items()}\n",
    "        for user_id in tqdm(users, desc=\"Predicting with ItemKNN (Annoy)\"):\n",
    "            if user_id not in self.user_id_map:\n",
    "                predictions[user_id] = popular_items[:k]\n",
    "                continue\n",
    "            user_idx = self.user_id_map[user_id]\n",
    "            user_items = self.user_item_matrix[user_idx].indices\n",
    "            item_scores = defaultdict(float)\n",
    "            for item_idx in user_items:\n",
    "                similar_items, distances = self.item_index.get_nns_by_item(item_idx, self.n_neighbors + 1, include_distances=True)\n",
    "                similar_items = similar_items[1:]\n",
    "                distances = distances[1:]\n",
    "                for sim_idx, dist in zip(similar_items, distances):\n",
    "                    sim_score = 1 - dist / 2\n",
    "                    item_scores[sim_idx] += sim_score\n",
    "            user_known_items = set(user_items)\n",
    "            top_items = sorted(item_scores.items(), key=lambda x: -x[1])[:k]\n",
    "            # Для отладки: закомментировать фильтрацию\n",
    "            # top_items = [item_idx for item_idx, _ in top_items if item_idx not in user_known_items]\n",
    "            predictions[user_id] = [reverse_item_map[item_idx] for item_idx, _ in top_items] if top_items else popular_items[:k]\n",
    "            if len(predictions[user_id]) == 0 and user_id == users[0]:\n",
    "                print(f\"Debug for user {user_id}: item_scores len: {len(item_scores)}, known_items len: {len(user_known_items)}, top_items before filter: {len(sorted(item_scores.items(), key=lambda x: -x[1])[:k])}\")\n",
    "        gc.collect()\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb8b02",
   "metadata": {},
   "source": [
    "#### Вспомогательные функции для удобного представления результатов\n",
    "\n",
    "Необходимы для составления табличек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce3f56bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shorten_list(lst, max_len=10):\n",
    "    \"\"\"Обрезает длинные списки для красивого вывода\"\"\"\n",
    "    if lst is None:\n",
    "        return []\n",
    "    return lst[:max_len] if len(lst) > max_len else lst\n",
    "\n",
    "def show_predictions(models: dict, data: pl.DataFrame, n=5, verbose=True, is_val=False):\n",
    "    df = data.sample(n).select([\"user_id\", \"item_id\"])\n",
    "    if is_val:\n",
    "        df = df.rename({\"item_id\": \"true_items\"})\n",
    "\n",
    "    # добавляем предсказания\n",
    "    for name, preds in models.items():\n",
    "        df = df.with_columns(\n",
    "            pl.col(\"user_id\").map_elements(\n",
    "                lambda u: _shorten_list(preds.get(u, [])), \n",
    "                return_dtype=pl.List(pl.Int64)\n",
    "            ).alias(name)\n",
    "        )\n",
    "\n",
    "    if verbose:\n",
    "        print(df.shape)\n",
    "        print(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def val_predictions(models: dict, val: pl.DataFrame, validator: Validator, k: int = 10, verbose: bool = True):\n",
    "    results = []\n",
    "    user2items = (\n",
    "        val.group_by(\"user_id\").agg(pl.col(\"item_id\")).to_dict(as_series=False)\n",
    "    )\n",
    "    user2items = dict(zip(user2items[\"user_id\"], user2items[\"item_id\"]))\n",
    "\n",
    "    for model_name, preds in models.items():\n",
    "        recalls, precisions, hits, ndcgs, mrrs = [], [], [], [], []\n",
    "        for u, y_true in user2items.items():\n",
    "            y_pred = preds.get(u, [])\n",
    "            recalls.append(validator.recall_at_k(y_true, y_pred, k))\n",
    "            precisions.append(validator.precision_at_k(y_true, y_pred, k))\n",
    "            hits.append(validator.hitrate_at_k(y_true, y_pred, k))\n",
    "            ndcgs.append(validator.ndcg_at_k(y_true, y_pred, k))\n",
    "            mrrs.append(validator.mrr_at_k(y_true, y_pred, k))\n",
    "        metrics = {\n",
    "            \"model\": model_name,\n",
    "            \"Recall@10\": np.mean(recalls),\n",
    "            \"Precision@10\": np.mean(precisions),\n",
    "            \"HitRate@10\": np.mean(hits),\n",
    "            \"NDCG@10\": np.mean(ndcgs),\n",
    "            \"MRR@10\": np.mean(mrrs),\n",
    "            \"Coverage\": validator.coverage(preds),\n",
    "        }\n",
    "        results.append(metrics)\n",
    "\n",
    "    df = pl.DataFrame(results)\n",
    "    if verbose:\n",
    "        print(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffc5ce4",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e1a315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train users: 349719, items: 31300\n",
      "Test users: 185828, items: 27367\n",
      "Cold items: 1775\n",
      "Popular items: [30197, 4058, 15514, 18150, 118, 13064, 33370, 15009, 960, 27745]\n",
      "Using 80816 common users for prediction\n",
      "Sample user: 6548c26be062f57a4105de9a5bfa358b\n",
      "In train_sample: True\n",
      "Train interactions: [3513, 13899, 28589, 31390, 28109, 18355, 12854, 24417]\n",
      "Test interactions: [1948, 6061, 6201, 10024, 14425, 16848, 21421, 26498, 29110, 31820]\n",
      "Unique users: 107586, Unique items: 16386\n",
      "User-item matrix shape: (107586, 16386)\n",
      "User-item matrix memory usage: 7.93 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Annoy index for users: 100%|██████████| 107586/107586 [01:06<00:00, 1624.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annoy index for users built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting with UserKNN (Annoy): 100%|██████████| 80816/80816 [00:03<00:00, 21945.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ../predictions/user_knn_predictions_sample.pkl (pickle format)\n",
      "Predictions also saved to ../predictions/user_knn_predictions_sample.json (JSON format)\n",
      "Unique users: 107586, Unique items: 16386\n",
      "User-item matrix shape: (107586, 16386)\n",
      "User-item matrix memory usage: 7.93 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Annoy index for items: 100%|██████████| 16386/16386 [01:33<00:00, 174.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annoy index for items built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting with ItemKNN (Annoy): 100%|██████████| 80816/80816 [01:54<00:00, 705.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ../predictions/item_knn_predictions_sample.pkl (pickle format)\n",
      "Predictions also saved to ../predictions/item_knn_predictions_sample.json (JSON format)\n",
      "\n",
      "Рекомендации моделей:\n",
      "(5, 4)\n",
      "shape: (5, 4)\n",
      "┌─────────────────────────────────┬─────────┬────────────────────────┬────────────────────────┐\n",
      "│ user_id                         ┆ item_id ┆ ItemKNN                ┆ UserKNN                │\n",
      "│ ---                             ┆ ---     ┆ ---                    ┆ ---                    │\n",
      "│ str                             ┆ i64     ┆ list[i64]              ┆ list[i64]              │\n",
      "╞═════════════════════════════════╪═════════╪════════════════════════╪════════════════════════╡\n",
      "│ 9e807829c237765ead132c67a7cbac… ┆ 19605   ┆ [30197, 4058, … 27745] ┆ [30197, 4058, … 27745] │\n",
      "│ 7bf2aad1b2d5690aace6334ff99409… ┆ 4058    ┆ []                     ┆ []                     │\n",
      "│ d9ffd88941bab3f6f89dcf41e5f2f7… ┆ 28438   ┆ []                     ┆ []                     │\n",
      "│ f0e911936de2115a609c05a447d200… ┆ 7113    ┆ [30197, 4058, … 27745] ┆ [30197, 4058, … 27745] │\n",
      "│ beb1d413926bc7514b348e191440d4… ┆ 29760   ┆ []                     ┆ []                     │\n",
      "└─────────────────────────────────┴─────────┴────────────────────────┴────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train users: {train['user_id'].n_unique()}, items: {len(train_items)}\")\n",
    "print(f\"Test users: {test['user_id'].n_unique()}, items: {len(test_items)}\")\n",
    "print(f\"Cold items: {len(cold_items)}\")\n",
    "\n",
    "# Вычисляем популярные айтемы\n",
    "popular_items = train_sample.group_by(\"item_id\").agg(pl.col(\"user_id\").count().alias(\"count\")).sort(\"count\", descending=True).head(10)[\"item_id\"].to_list()\n",
    "print(f\"Popular items: {popular_items}\")\n",
    "\n",
    "# Ограничиваем user_ids общими пользователями\n",
    "user_ids = list(common_users)\n",
    "print(f\"Using {len(user_ids)} common users for prediction\")\n",
    "\n",
    "# Диагностика sample пользователя\n",
    "if user_ids:\n",
    "    sample_user = user_ids[0]\n",
    "else:\n",
    "    sample_user = test[\"user_id\"][0]\n",
    "print(f\"Sample user: {sample_user}\")\n",
    "print(f\"In train_sample: {sample_user in train_sample['user_id']}\")\n",
    "print(f\"Train interactions: {train_sample.filter(pl.col('user_id') == sample_user)['item_id'].to_list()}\")\n",
    "print(f\"Test interactions: {test.filter(pl.col('user_id') == sample_user)['item_id'].to_list()}\")\n",
    "\n",
    "# Инициализируем и обучаем разные модели\n",
    "user_knn = UserKNN(n_neighbors=5, n_trees=5)\n",
    "user_knn.fit(train_sample)\n",
    "pred_user_knn = user_knn.predict(user_ids, k=10)\n",
    "user_knn.save_predictions(pred_user_knn, \"../predictions/user_knn_predictions_sample.pkl\")\n",
    "\n",
    "item_knn = ItemKNN(n_neighbors=5, n_trees=5)\n",
    "item_knn.fit(train_sample)\n",
    "pred_item_knn = item_knn.predict(user_ids, k=10)\n",
    "item_knn.save_predictions(pred_item_knn, \"../predictions/item_knn_predictions_sample.pkl\")\n",
    "\n",
    "# Собираем предсказания в словарь\n",
    "models = {\n",
    "    \"ItemKNN\": pred_item_knn,\n",
    "    \"UserKNN\": pred_user_knn,\n",
    "}\n",
    "\n",
    "print(\"\\nРекомендации моделей:\")\n",
    "train_df = show_predictions(models, train, n=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d54da2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Статистика по метрикам для каждой модели:\n",
      "shape: (2, 7)\n",
      "┌─────────┬───────────┬──────────────┬────────────┬──────────┬──────────┬──────────┐\n",
      "│ model   ┆ Recall@10 ┆ Precision@10 ┆ HitRate@10 ┆ NDCG@10  ┆ MRR@10   ┆ Coverage │\n",
      "│ ---     ┆ ---       ┆ ---          ┆ ---        ┆ ---      ┆ ---      ┆ ---      │\n",
      "│ str     ┆ f64       ┆ f64          ┆ f64        ┆ f64      ┆ f64      ┆ f64      │\n",
      "╞═════════╪═══════════╪══════════════╪════════════╪══════════╪══════════╪══════════╡\n",
      "│ ItemKNN ┆ 0.007577  ┆ 0.011601     ┆ 0.08143    ┆ 0.013184 ┆ 0.030187 ┆ 0.000319 │\n",
      "│ UserKNN ┆ 0.007577  ┆ 0.011601     ┆ 0.08143    ┆ 0.013184 ┆ 0.030187 ┆ 0.000319 │\n",
      "└─────────┴───────────┴──────────────┴────────────┴──────────┴──────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nСтатистика по метрикам для каждой модели:\")\n",
    "validator = JointValidator(train, test, cold_items)\n",
    "metrics_df = val_predictions(models, test, validator, k=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92d99bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common users between train_sample and test: 80816\n",
      "Percentage of test users in train_sample: 43.49%\n"
     ]
    }
   ],
   "source": [
    "train_users = set(train_sample[\"user_id\"].unique())\n",
    "test_users = set(test[\"user_id\"].unique())\n",
    "common_users = train_users.intersection(test_users)\n",
    "print(f\"Common users between train_sample and test: {len(common_users)}\")\n",
    "print(f\"Percentage of test users in train_sample: {len(common_users) / len(test_users) * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
