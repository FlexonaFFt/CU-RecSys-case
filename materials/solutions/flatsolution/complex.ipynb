{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bc2ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import pickle\n",
    "import joblib\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fed5211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import implicit\n",
    "    HAS_IMPLICIT = True\n",
    "except Exception:\n",
    "    HAS_IMPLICIT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4957690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_genres_list(g):\n",
    "    # Handle iterable types first to avoid ambiguous truth value in pd.isna\n",
    "    if isinstance(g, list):\n",
    "        return g\n",
    "    if isinstance(g, (tuple, set)):\n",
    "        return list(g)\n",
    "    if isinstance(g, np.ndarray):\n",
    "        return list(g.tolist())\n",
    "\n",
    "    # Now handle missing/NaN\n",
    "    if g is None:\n",
    "        return []\n",
    "    if isinstance(g, float) and pd.isna(g):\n",
    "        return []\n",
    "\n",
    "    # Parse strings like \"a|b\" or \"a, b\"\n",
    "    if isinstance(g, str):\n",
    "        if '|' in g:\n",
    "            return [x.strip() for x in g.split('|') if x.strip()]\n",
    "        return [x.strip() for x in g.split(',') if x.strip()]\n",
    "\n",
    "    # Best-effort fallback\n",
    "    try:\n",
    "        return list(g)\n",
    "    except Exception:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7aa68bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mappings(interactions: pd.DataFrame, items: pd.DataFrame):\n",
    "    users = interactions['user_id'].unique().tolist()\n",
    "    items_list = items['item_id'].unique().tolist()\n",
    "    user2idx = {u: i for i, u in enumerate(users)}\n",
    "    idx2user = {i: u for u, i in user2idx.items()}\n",
    "    item2idx = {it: i for i, it in enumerate(items_list)}\n",
    "    idx2item = {i: it for it, i in item2idx.items()}\n",
    "    return user2idx, idx2user, item2idx, idx2item\n",
    "\n",
    "\n",
    "def build_user_item_matrix(interactions: pd.DataFrame, user2idx, item2idx, implicit=True):\n",
    "    n_users = len(user2idx)\n",
    "    n_items = len(item2idx)\n",
    "    mat = np.zeros((n_users, n_items), dtype=float)\n",
    "    for _, row in interactions.iterrows():\n",
    "        u = row['user_id']\n",
    "        it = row['item_id']\n",
    "        if u not in user2idx or it not in item2idx:\n",
    "            continue\n",
    "        ui = user2idx[u]\n",
    "        ii = item2idx[it]\n",
    "        if 'rating' in row and not implicit:\n",
    "            val = float(row['rating']) if not pd.isna(row['rating']) else 0.0\n",
    "        else:\n",
    "            val = 1.0\n",
    "        mat[ui, ii] += val\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "823a4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(recommended: List[str], ground_truth: set, k: int) -> float:\n",
    "    if k == 0:\n",
    "        return 0.0\n",
    "    recommended_k = recommended[:k]\n",
    "    if not recommended_k:\n",
    "        return 0.0\n",
    "    hits = sum(1 for r in recommended_k if r in ground_truth)\n",
    "    return hits / k\n",
    "\n",
    "\n",
    "def recall_at_k(recommended: List[str], ground_truth: set, k: int) -> float:\n",
    "    if not ground_truth:\n",
    "        return 0.0\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = sum(1 for r in recommended_k if r in ground_truth)\n",
    "    return hits / len(ground_truth)\n",
    "\n",
    "\n",
    "def dcg_at_k(recommended: List[str], ground_truth: set, k: int) -> float:\n",
    "    dcg = 0.0\n",
    "    for i, r in enumerate(recommended[:k]):\n",
    "        rel = 1.0 if r in ground_truth else 0.0\n",
    "        denom = math.log2(i + 2)\n",
    "        dcg += rel / denom\n",
    "    return dcg\n",
    "\n",
    "\n",
    "def ndcg_at_k(recommended: List[str], ground_truth: set, k: int) -> float:\n",
    "    idcg = 0.0\n",
    "    # ideal DCG: put all ground truth items at top\n",
    "    ideal_hits = min(len(ground_truth), k)\n",
    "    for i in range(ideal_hits):\n",
    "        idcg += 1.0 / math.log2(i + 2)\n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "    return dcg_at_k(recommended, ground_truth, k) / idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85f442ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_leave_one_out(interactions: pd.DataFrame, by_time_col: Optional[str]=None, seed: int=42) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    For each user, leave one interaction for test. If `by_time_col` provided, choose the latest interaction.\n",
    "    Otherwise choose a random interaction as test for each user with >=2 interactions.\n",
    "    Users with only 1 interaction will have test empty (or can be handled separately).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    train_rows = []\n",
    "    test_rows = []\n",
    "    grouped = interactions.groupby('user_id')\n",
    "    for user, group in grouped:\n",
    "        if by_time_col and by_time_col in group.columns:\n",
    "            group_sorted = group.sort_values(by=by_time_col)\n",
    "            test_idx = group_sorted.index[-1]\n",
    "        else:\n",
    "            if len(group) == 1:\n",
    "                # keep in train to avoid empty training\n",
    "                test_idx = None\n",
    "            else:\n",
    "                test_idx = rng.choice(group.index)\n",
    "        for idx, row in group.iterrows():\n",
    "            if idx == test_idx:\n",
    "                test_rows.append(row.to_dict())\n",
    "            else:\n",
    "                train_rows.append(row.to_dict())\n",
    "    train_df = pd.DataFrame(train_rows)\n",
    "    test_df = pd.DataFrame(test_rows)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "945af43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopularityRecommender:\n",
    "    def __init__(self):\n",
    "        self.pop_scores = None\n",
    "        self.item_order = None\n",
    "\n",
    "    def fit(self, interactions: pd.DataFrame, item2idx: Dict[str,int]):\n",
    "        # compute popularity by item counts in interactions\n",
    "        counts = interactions['item_id'].value_counts()\n",
    "        # map to item list order\n",
    "        self.pop_scores = counts.to_dict()\n",
    "        # fallback to items not present\n",
    "        self.item_order = [it for it, _ in counts.items()]\n",
    "\n",
    "    def recommend(self, user_id: str, seen: set, top_k: int=20):\n",
    "        recs = []\n",
    "        for it in self.item_order:\n",
    "            if it in seen:\n",
    "                continue\n",
    "            recs.append(it)\n",
    "            if len(recs) >= top_k:\n",
    "                break\n",
    "        return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "948eaf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVDRecommender:\n",
    "    def __init__(self, n_factors: int=50, random_state: int=42):\n",
    "        self.n_factors = n_factors\n",
    "        self.random_state = random_state\n",
    "        self.user_factors = None\n",
    "        self.item_factors = None\n",
    "        self.svd = None\n",
    "\n",
    "    def fit(self, train_mat: np.ndarray):\n",
    "        n_components = min(self.n_factors, min(train_mat.shape)-1)\n",
    "        svd = TruncatedSVD(n_components=n_components, random_state=self.random_state)\n",
    "        U = svd.fit_transform(train_mat)\n",
    "        Vt = svd.components_\n",
    "        self.user_factors = U\n",
    "        self.item_factors = Vt.T\n",
    "        self.svd = svd\n",
    "\n",
    "    def recommend(self, user_idx: int, seen_idx: set, idx2item: Dict[int,str], top_k: int=20):\n",
    "        if self.user_factors is None or self.item_factors is None:\n",
    "            return []\n",
    "        scores = self.user_factors[user_idx].dot(self.item_factors.T)\n",
    "        candidates = []\n",
    "        for iid, sc in enumerate(scores):\n",
    "            if iid in seen_idx:\n",
    "                continue\n",
    "            candidates.append((iid, sc))\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [idx2item[iid] for iid, _ in candidates[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5580634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALSRecommender:\n",
    "    def __init__(self, factors=50, regularization=0.01, iterations=20):\n",
    "        if not HAS_IMPLICIT:\n",
    "            raise RuntimeError('implicit library not available; install with `pip install implicit`')\n",
    "        self.model = implicit.als.AlternatingLeastSquares(factors=factors, regularization=regularization, iterations=iterations)\n",
    "        self.factors = factors\n",
    "\n",
    "    def fit(self, train_mat: np.ndarray, user2idx, item2idx):\n",
    "        # implicit expects item-user sparse matrix\n",
    "        from scipy.sparse import coo_matrix\n",
    "        item_user = coo_matrix(train_mat.T)\n",
    "        # train\n",
    "        self.model.fit(item_user)\n",
    "        # item factors are model.item_factors\n",
    "\n",
    "    def recommend(self, user_id, user2idx, idx2item, N=20):\n",
    "        uid = user2idx[user_id]\n",
    "        recs = self.model.recommend(uid, None, N=N)\n",
    "        # returns list of (item_idx, score)\n",
    "        return [idx2item[i] for i, _ in recs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "947de383",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphRecommender:\n",
    "    def __init__(self):\n",
    "        self.G = None\n",
    "\n",
    "    def build_graph(self, interactions: pd.DataFrame):\n",
    "        G = nx.Graph()\n",
    "        # add nodes with prefixes\n",
    "        for u in interactions['user_id'].unique():\n",
    "            G.add_node(f'u_{u}', bipartite=0)\n",
    "        for it in interactions['item_id'].unique():\n",
    "            G.add_node(f'i_{it}', bipartite=1)\n",
    "        for _, r in interactions.iterrows():\n",
    "            G.add_edge(f\"u_{r['user_id']}\", f\"i_{r['item_id']}\")\n",
    "\n",
    "        self.G = G\n",
    "\n",
    "    def recommend(self, user_id: str, seen: set, top_k: int=20, alpha: float=0.85):\n",
    "        if self.G is None:\n",
    "            return []\n",
    "        start = f'u_{user_id}'\n",
    "        if start not in self.G:\n",
    "            return []\n",
    "        pr = nx.pagerank(self.G, alpha=alpha, personalization={start: 1.0})\n",
    "        items_scores = []\n",
    "        for node, sc in pr.items():\n",
    "            if node.startswith('i_'):\n",
    "                it = node[2:]\n",
    "                if it in seen:\n",
    "                    continue\n",
    "                items_scores.append((it, sc))\n",
    "        items_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [it for it, _ in items_scores[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5c04692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_by_genre_author(item_id: str, items_df: pd.DataFrame, item2idx: Dict[str,int], pop_scores: Dict[str,float], top_k: int=10):\n",
    "    if item_id not in items_df['item_id'].values:\n",
    "        return []\n",
    "    row = items_df[items_df['item_id']==item_id].iloc[0]\n",
    "    genres = set(row['genres'])\n",
    "    author = row.get('author', None)\n",
    "    candidates = []\n",
    "    for _, r in items_df.iterrows():\n",
    "        if r['item_id'] == item_id:\n",
    "            continue\n",
    "        score = len(set(r['genres']) & genres)\n",
    "        if author and r.get('author')==author:\n",
    "            score += 1\n",
    "        pop = pop_scores.get(r['item_id'], 0.0)\n",
    "        candidates.append((r['item_id'], score, pop))\n",
    "    candidates.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
    "    return [c[0] for c in candidates[:top_k]]\n",
    "\n",
    "\n",
    "def cold_start_for_user(user_id: str, items_df: pd.DataFrame, user_train_interactions: pd.DataFrame, pop_scores: Dict[str,float], top_k: int=20):\n",
    "    user_items = user_train_interactions[user_train_interactions['user_id']==user_id]['item_id'].tolist()\n",
    "    if not user_items:\n",
    "        # global popular\n",
    "        ordered = sorted(pop_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return [it for it, _ in ordered[:top_k]]\n",
    "    # infer genres\n",
    "    genres = Counter()\n",
    "    for it in user_items:\n",
    "        gs = items_df[items_df['item_id']==it]['genres'].iloc[0]\n",
    "        for g in gs:\n",
    "            genres[g]+=1\n",
    "    top_genres = set([g for g,_ in genres.most_common(3)])\n",
    "    candidates = []\n",
    "    for _, r in items_df.iterrows():\n",
    "        overlap = len(set(r['genres']) & top_genres)\n",
    "        pop = pop_scores.get(r['item_id'], 0.0)\n",
    "        score = overlap + 0.2*pop\n",
    "        candidates.append((r['item_id'], score))\n",
    "    candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [c[0] for c in candidates[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b579fd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(train_interactions: pd.DataFrame, test_interactions: pd.DataFrame, items: pd.DataFrame, models: Dict[str, object], k_list: List[int]=[5,10,20], save_dir: str='models') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    models: dict with keys as model names and values as objects exposing .fit and .recommend or custom callables.\n",
    "    For SVD/ALS/Popularity/Graph we adhere to the interfaces above.\n",
    "    Returns DataFrame with metrics per model per k.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    # prepare mappings and matrices\n",
    "    user2idx, idx2user, item2idx, idx2item = build_mappings(train_interactions, items)\n",
    "    train_mat = build_user_item_matrix(train_interactions, user2idx, item2idx)\n",
    "    # popularity scores\n",
    "    pop_counts = train_interactions['item_id'].value_counts().to_dict()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # fit all models\n",
    "    for name, model in models.items():\n",
    "        print('Fitting', name)\n",
    "        if name == 'popularity':\n",
    "            model.fit(train_interactions, item2idx)\n",
    "        elif name == 'svd':\n",
    "            model.fit(train_mat)\n",
    "        elif name == 'als':\n",
    "            if HAS_IMPLICIT:\n",
    "                model.fit(train_mat, user2idx, item2idx)\n",
    "            else:\n",
    "                print('Skipping ALS (implicit not installed)')\n",
    "                continue\n",
    "        elif name == 'graph':\n",
    "            model.build_graph(train_interactions)\n",
    "        # save model artifacts\n",
    "        model_path = os.path.join(save_dir, f'{name}.pkl')\n",
    "        try:\n",
    "            joblib.dump(model, model_path)\n",
    "        except Exception as e:\n",
    "            print('Could not save model via joblib:', e)\n",
    "        # if graph, also save graph separately\n",
    "        if name == 'graph' and hasattr(model, 'G') and model.G is not None:\n",
    "            gp_path = os.path.join(save_dir, 'graph.gpickle')\n",
    "            try:\n",
    "                with open(gp_path, 'wb') as f:\n",
    "                    pickle.dump(model.G, f)\n",
    "            except Exception as e:\n",
    "                print('Could not pickle graph:', e)\n",
    "\n",
    "    # evaluate per user in test set\n",
    "    test_grouped = test_interactions.groupby('user_id')\n",
    "    users_eval = list(test_grouped.groups.keys())\n",
    "    # We'll restrict to users present in train mappings\n",
    "    users_eval = [u for u in users_eval if u in user2idx]\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print('Evaluating', name)\n",
    "        # accumulate per-k metrics\n",
    "        metrics_acc = {k: {'precision':[], 'recall':[], 'ndcg':[]} for k in k_list}\n",
    "        for user in users_eval:\n",
    "            uidx = user2idx[user]\n",
    "            # seen items (train)\n",
    "            seen_idx = set(np.where(train_mat[uidx] > 0)[0])\n",
    "            seen = set([idx2item[i] for i in seen_idx])\n",
    "            # ground truth (test items for user)\n",
    "            ground_truth = set(test_grouped.get_group(user)['item_id'].tolist())\n",
    "            if not ground_truth:\n",
    "                continue\n",
    "            # get recommendations (model-specific)\n",
    "            if name == 'popularity':\n",
    "                recs = model.recommend(user, seen, top_k=max(k_list))\n",
    "            elif name == 'svd':\n",
    "                recs = model.recommend(uidx, seen_idx, idx2item, top_k=max(k_list))\n",
    "            elif name == 'als':\n",
    "                if not HAS_IMPLICIT:\n",
    "                    continue\n",
    "                recs = model.recommend(user, user2idx, idx2item, N=max(k_list))\n",
    "            elif name == 'graph':\n",
    "                recs = model.recommend(user, seen, top_k=max(k_list))\n",
    "            else:\n",
    "                # custom callable\n",
    "                try:\n",
    "                    recs = model(user, top_k=max(k_list))\n",
    "                except Exception:\n",
    "                    recs = []\n",
    "            for k in k_list:\n",
    "                p = precision_at_k(recs, ground_truth, k)\n",
    "                r = recall_at_k(recs, ground_truth, k)\n",
    "                n = ndcg_at_k(recs, ground_truth, k)\n",
    "                metrics_acc[k]['precision'].append(p)\n",
    "                metrics_acc[k]['recall'].append(r)\n",
    "                metrics_acc[k]['ndcg'].append(n)\n",
    "        # aggregate\n",
    "        for k in k_list:\n",
    "            if len(metrics_acc[k]['precision'])==0:\n",
    "                avg_p = avg_r = avg_n = 0.0\n",
    "            else:\n",
    "                avg_p = float(np.mean(metrics_acc[k]['precision']))\n",
    "                avg_r = float(np.mean(metrics_acc[k]['recall']))\n",
    "                avg_n = float(np.mean(metrics_acc[k]['ndcg']))\n",
    "            results.append({'model':name, 'k':k, 'precision':avg_p, 'recall':avg_r, 'ndcg':avg_n})\n",
    "    res_df = pd.DataFrame(results)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b10146e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting popularity\n",
      "Fitting svd\n",
      "Fitting graph\n",
      "Evaluating popularity\n",
      "Evaluating svd\n",
      "Evaluating graph\n",
      "        model  k  precision  recall      ndcg\n",
      "0  popularity  1   0.000000     0.0  0.000000\n",
      "1  popularity  3   0.000000     0.0  0.000000\n",
      "2         svd  1   0.000000     0.0  0.000000\n",
      "3         svd  3   0.333333     1.0  0.565465\n",
      "4       graph  1   0.000000     0.0  0.000000\n",
      "5       graph  3   0.000000     0.0  0.000000\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # small synthetic example\n",
    "    items = pd.DataFrame([\n",
    "        {'item_id':'b1','title':'Book A','genres':['Fantasy','Adventure'],'author':'Auth1'},\n",
    "        {'item_id':'b2','title':'Book B','genres':['Sci-Fi'],'author':'Auth2'},\n",
    "        {'item_id':'b3','title':'Book C','genres':['Fantasy'],'author':'Auth3'},\n",
    "        {'item_id':'b4','title':'Book D','genres':['History'],'author':'Auth2'},\n",
    "        {'item_id':'b5','title':'Book E','genres':['Sci-Fi','Adventure'],'author':'Auth1'}\n",
    "    ])\n",
    "    interactions = pd.DataFrame([\n",
    "        {'user_id':'u1','item_id':'b1'},\n",
    "        {'user_id':'u1','item_id':'b3'},\n",
    "        {'user_id':'u2','item_id':'b2'},\n",
    "        {'user_id':'u2','item_id':'b5'},\n",
    "        {'user_id':'u3','item_id':'b4'},\n",
    "    ])\n",
    "\n",
    "    # normalize genres\n",
    "    items['genres'] = items['genres'].apply(ensure_genres_list)\n",
    "\n",
    "    train, test = train_test_split_leave_one_out(interactions)\n",
    "\n",
    "    user2idx, idx2user, item2idx, idx2item = build_mappings(train, items)\n",
    "    train_mat = build_user_item_matrix(train, user2idx, item2idx)\n",
    "\n",
    "    # instantiate models\n",
    "    pop = PopularityRecommender()\n",
    "    svd = SVDRecommender(n_factors=2)\n",
    "    graph = GraphRecommender()\n",
    "\n",
    "    models = {'popularity': pop, 'svd': svd, 'graph': graph}\n",
    "\n",
    "    res = evaluate_models(train, test, items, models, k_list=[1,3])\n",
    "    print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
