{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda0548a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "try:\n",
    "    import implicit\n",
    "    HAS_IMPLICIT = True\n",
    "except Exception:\n",
    "    HAS_IMPLICIT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c3e5cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../../../data/\"\n",
    "train = pl.read_parquet(data_folder + \"train.pq\")\n",
    "test_exploded = pl.read_parquet(data_folder + \"test.pq\")\n",
    "test = test_exploded.group_by(\"user_id\", maintain_order=True).agg(pl.col(\"item_id\"))\n",
    "books = pl.read_parquet(data_folder + \"books.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d097e292",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = train.to_pandas()\n",
    "test_pd = test.to_pandas()\n",
    "books_pd = books.to_pandas()\n",
    "\n",
    "# Приведение типов\n",
    "# Преобразуем user_id и item_id в строку (если вдруг числа — всё равно ок)\n",
    "train_pd[\"user_id\"] = train_pd[\"user_id\"].astype(str)\n",
    "train_pd[\"item_id\"] = train_pd[\"item_id\"].astype(str)\n",
    "test_pd[\"user_id\"] = test_pd[\"user_id\"].astype(str)\n",
    "books_pd[\"item_id\"] = books_pd[\"item_id\"].astype(str)\n",
    "\n",
    "# Собираем уникальные id\n",
    "user_ids = train_pd[\"user_id\"].unique()\n",
    "item_ids = train_pd[\"item_id\"].unique()\n",
    "\n",
    "# Маппинги\n",
    "user_to_idx = {u: i for i, u in enumerate(user_ids)}\n",
    "idx_to_user = {i: u for u, i in user_to_idx.items()}\n",
    "item_to_idx = {i: j for j, i in enumerate(item_ids)}\n",
    "idx_to_item = {j: i for i, j in item_to_idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3220b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopularityRecommender:\n",
    "    def __init__(self):\n",
    "        self.popularity = None\n",
    "\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        self.popularity = df[\"item_id\"].value_counts().to_dict()\n",
    "        return self\n",
    "\n",
    "    def recommend(self, user_id: int, top_k: int = 10):\n",
    "        return [i for i, _ in Counter(self.popularity).most_common(top_k)]\n",
    "\n",
    "    def save(self, path: str):\n",
    "        joblib.dump(self.popularity, path)\n",
    "\n",
    "    def load(self, path: str):\n",
    "        self.popularity = joblib.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e032e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVDRecommender:\n",
    "    def __init__(self, n_components=50):\n",
    "        self.n_components = n_components\n",
    "        self.svd = None\n",
    "        self.user_factors = None\n",
    "        self.item_factors = None\n",
    "\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        matrix = np.zeros((len(user_ids), len(item_ids)))\n",
    "        for row in df.itertuples():\n",
    "            matrix[user_to_idx[row.user_id], item_to_idx[row.item_id]] = 1\n",
    "\n",
    "        self.svd = TruncatedSVD(n_components=self.n_components, random_state=42)\n",
    "        self.user_factors = self.svd.fit_transform(matrix)\n",
    "        self.item_factors = self.svd.components_.T\n",
    "        return self\n",
    "\n",
    "    def recommend(self, user_id: int, top_k: int = 10):\n",
    "        if user_id not in user_to_idx:\n",
    "            return []\n",
    "        uvec = self.user_factors[user_to_idx[user_id]]\n",
    "        scores = self.item_factors.dot(uvec)\n",
    "        top_items = np.argsort(scores)[::-1][:top_k]\n",
    "        return [item_ids[i] for i in top_items]\n",
    "\n",
    "    def save(self, path: str):\n",
    "        joblib.dump(self.svd, path)\n",
    "\n",
    "    def load(self, path: str):\n",
    "        self.svd = joblib.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d5e1517",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_IMPLICIT:\n",
    "    from scipy.sparse import csr_matrix\n",
    "    from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "    class ALSRecommender:\n",
    "        def __init__(self, factors=50):\n",
    "            self.factors = factors\n",
    "            self.model = AlternatingLeastSquares(factors=factors)\n",
    "\n",
    "        def fit(self, df: pd.DataFrame):\n",
    "            rows = df[\"user_id\"].map(user_to_idx)\n",
    "            cols = df[\"item_id\"].map(item_to_idx)\n",
    "            data = np.ones(len(df))\n",
    "            mat = csr_matrix((data, (rows, cols)), shape=(len(user_ids), len(item_ids)))\n",
    "            self.model.fit(mat)\n",
    "            return self\n",
    "\n",
    "        def recommend(self, user_id: int, top_k: int = 10):\n",
    "            if user_id not in user_to_idx:\n",
    "                return []\n",
    "            recs, _ = self.model.recommend(user_to_idx[user_id], csr_matrix((1, len(item_ids))), N=top_k)\n",
    "            return [idx_to_item[i] for i in recs]\n",
    "\n",
    "        def save(self, path: str):\n",
    "            joblib.dump(self.model, path)\n",
    "\n",
    "        def load(self, path: str):\n",
    "            self.model = joblib.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1f1b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphRecommender:\n",
    "    def __init__(self):\n",
    "        self.G = nx.Graph()\n",
    "\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        for r in df.itertuples():\n",
    "            self.G.add_edge(f\"u_{r.user_id}\", f\"i_{r.item_id}\")\n",
    "        return self\n",
    "\n",
    "    def recommend(self, user_id: int, top_k: int = 10):\n",
    "        start_node = f\"u_{user_id}\"\n",
    "        if start_node not in self.G:\n",
    "            return []\n",
    "        pr = nx.pagerank(self.G, alpha=0.85, personalization={start_node: 1})\n",
    "        recs = [n for n in sorted(pr, key=pr.get, reverse=True) if n.startswith(\"i_\")]\n",
    "        return [int(n[2:]) for n in recs[:top_k]]\n",
    "\n",
    "    def save(self, path: str):\n",
    "        nx.write_gpickle(self.G, path)\n",
    "\n",
    "    def load(self, path: str):\n",
    "        self.G = nx.read_gpickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3834d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_cold(item_id: int, top_k: int = 10):\n",
    "    if item_id not in books_pd[\"item_id\"].values:\n",
    "        return []\n",
    "    genre = books_pd.loc[books_pd[\"item_id\"] == item_id, \"genre\"].values[0]\n",
    "    candidates = books_pd[books_pd[\"genre\"] == genre][\"item_id\"].tolist()\n",
    "    return candidates[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be032d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(pred: List[int], true: List[int], k: int = 10) -> float:\n",
    "    return len(set(pred[:k]) & set(true)) / k\n",
    "\n",
    "def recall_at_k(pred: List[int], true: List[int], k: int = 10) -> float:\n",
    "    return len(set(pred[:k]) & set(true)) / max(1, len(true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23a5d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(train_df: pd.DataFrame, test_df: pd.DataFrame, models: Dict[str, object], top_k: int = 10, save_dir: str = \"models\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    results = []\n",
    "\n",
    "    def ensure_list(x):\n",
    "        if isinstance(x, (list, tuple)):\n",
    "            return list(x)\n",
    "        if isinstance(x, np.ndarray):\n",
    "            return x.tolist()\n",
    "        return [x]\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        model.fit(train_df)\n",
    "        model_path = os.path.join(save_dir, f\"{name}.joblib\")\n",
    "        try:\n",
    "            model.save(model_path)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        precisions, recalls = [], []\n",
    "        for row in test_df.itertuples():\n",
    "            uid = row.user_id\n",
    "            true_items = ensure_list(row.item_id)\n",
    "            preds = model.recommend(uid, top_k=top_k)\n",
    "            precisions.append(precision_at_k(preds, true_items, top_k))\n",
    "            recalls.append(recall_at_k(preds, true_items, top_k))\n",
    "\n",
    "        results.append({\n",
    "            \"model\": name,\n",
    "            \"precision@k\": np.mean(precisions),\n",
    "            \"recall@k\": np.mean(recalls)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d128b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training popularity...\n",
      "Training svd...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:335: RuntimeWarning: divide by zero encountered in matmul\n",
      "  Q, _ = normalizer(A @ Q)\n",
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:335: RuntimeWarning: overflow encountered in matmul\n",
      "  Q, _ = normalizer(A @ Q)\n",
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:335: RuntimeWarning: invalid value encountered in matmul\n",
      "  Q, _ = normalizer(A @ Q)\n",
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  Q, _ = normalizer(A.T @ Q)\n",
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  Q, _ = normalizer(A.T @ Q)\n",
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  Q, _ = normalizer(A.T @ Q)\n",
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:340: RuntimeWarning: divide by zero encountered in matmul\n",
      "  Q, _ = qr_normalizer(A @ Q)\n",
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:340: RuntimeWarning: overflow encountered in matmul\n",
      "  Q, _ = qr_normalizer(A @ Q)\n",
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:340: RuntimeWarning: invalid value encountered in matmul\n",
      "  Q, _ = qr_normalizer(A @ Q)\n",
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:533: RuntimeWarning: divide by zero encountered in matmul\n",
      "  B = Q.T @ M\n",
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:533: RuntimeWarning: overflow encountered in matmul\n",
      "  B = Q.T @ M\n",
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:533: RuntimeWarning: invalid value encountered in matmul\n",
      "  B = Q.T @ M\n",
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:547: RuntimeWarning: divide by zero encountered in matmul\n",
      "  U = Q @ Uhat\n",
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:547: RuntimeWarning: overflow encountered in matmul\n",
      "  U = Q @ Uhat\n",
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:547: RuntimeWarning: invalid value encountered in matmul\n",
      "  U = Q @ Uhat\n",
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/flexonafft/curecsys/myenv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"popularity\": PopularityRecommender(),\n",
    "    \"svd\": SVDRecommender(n_components=50),\n",
    "    \"graph\": GraphRecommender(),\n",
    "}\n",
    "if HAS_IMPLICIT:\n",
    "    models[\"als\"] = ALSRecommender(factors=50)\n",
    "\n",
    "results = evaluate_models(train_pd, test_pd, models, top_k=10, save_dir=\"models\")\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
